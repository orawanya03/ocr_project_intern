{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9ab825",
   "metadata": {},
   "source": [
    "## 1. Easy OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec97bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda3\\envs\\donut-th\\lib\\site-packages\\easyocr\\detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "c:\\Miniconda3\\envs\\donut-th\\lib\\site-packages\\easyocr\\recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ à¸à¸šà¸ à¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” 275 à¹„à¸Ÿà¸¥à¹Œ à¸à¸³à¸¥à¸±à¸‡à¹€à¸£à¸´à¹ˆà¸¡ OCR ...\n",
      "ğŸ“„ [1/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0001.jpg\n",
      "ğŸ“„ [2/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0002.jpg\n",
      "ğŸ“„ [3/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0003.jpg\n",
      "ğŸ“„ [4/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0004.jpg\n",
      "ğŸ“„ [5/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0005.jpg\n",
      "ğŸ“„ [6/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0006.jpg\n",
      "ğŸ“„ [7/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0007.jpg\n",
      "ğŸ“„ [8/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0008.jpg\n",
      "ğŸ“„ [9/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0009.jpg\n",
      "ğŸ“„ [10/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0010.jpg\n",
      "ğŸ“„ [11/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0011.jpg\n",
      "ğŸ“„ [12/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0012.jpg\n",
      "ğŸ“„ [13/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0013.jpg\n",
      "ğŸ“„ [14/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0014.jpg\n",
      "ğŸ“„ [15/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0015.jpg\n",
      "ğŸ“„ [16/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0016.jpg\n",
      "ğŸ“„ [17/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0017.jpg\n",
      "ğŸ“„ [18/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0018.jpg\n",
      "ğŸ“„ [19/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0019.jpg\n",
      "ğŸ“„ [20/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0020.jpg\n",
      "ğŸ“„ [21/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0021.jpg\n",
      "ğŸ“„ [22/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0022.jpg\n",
      "ğŸ“„ [23/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0023.jpg\n",
      "ğŸ“„ [24/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0024.jpg\n",
      "ğŸ“„ [25/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0025.jpg\n",
      "ğŸ“„ [26/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0026.jpg\n",
      "ğŸ“„ [27/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0027.jpg\n",
      "ğŸ“„ [28/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0028.jpg\n",
      "ğŸ“„ [29/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0029.jpg\n",
      "ğŸ“„ [30/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0030.jpg\n",
      "ğŸ“„ [31/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0031.jpg\n",
      "ğŸ“„ [32/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0032.jpg\n",
      "ğŸ“„ [33/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0033.jpg\n",
      "ğŸ“„ [34/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0034.jpg\n",
      "ğŸ“„ [35/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0035.jpg\n",
      "ğŸ“„ [36/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0036.jpg\n",
      "ğŸ“„ [37/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0037.jpg\n",
      "ğŸ“„ [38/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0038.jpg\n",
      "ğŸ“„ [39/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0039.jpg\n",
      "ğŸ“„ [40/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0040.jpg\n",
      "ğŸ“„ [41/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0041.jpg\n",
      "ğŸ“„ [42/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0042.jpg\n",
      "ğŸ“„ [43/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0043.jpg\n",
      "ğŸ“„ [44/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0044.jpg\n",
      "ğŸ“„ [45/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0045.jpg\n",
      "ğŸ“„ [46/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0046.jpg\n",
      "ğŸ“„ [47/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0047.jpg\n",
      "ğŸ“„ [48/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0048.jpg\n",
      "ğŸ“„ [49/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0049.jpg\n",
      "ğŸ“„ [50/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0050.jpg\n",
      "ğŸ“„ [51/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0051.jpg\n",
      "ğŸ“„ [52/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0052.jpg\n",
      "ğŸ“„ [53/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0053.jpg\n",
      "ğŸ“„ [54/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0054.jpg\n",
      "ğŸ“„ [55/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0055.jpg\n",
      "ğŸ“„ [56/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0056.jpg\n",
      "ğŸ“„ [57/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0057.jpg\n",
      "ğŸ“„ [58/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0058.jpg\n",
      "ğŸ“„ [59/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0059.jpg\n",
      "ğŸ“„ [60/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0060.jpg\n",
      "ğŸ“„ [61/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0061.jpg\n",
      "ğŸ“„ [62/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0062.jpg\n",
      "ğŸ“„ [63/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0063.jpg\n",
      "ğŸ“„ [64/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0064.jpg\n",
      "ğŸ“„ [65/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0065.jpg\n",
      "ğŸ“„ [66/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0066.jpg\n",
      "ğŸ“„ [67/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0067.jpg\n",
      "ğŸ“„ [68/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0068.jpg\n",
      "ğŸ“„ [69/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0069.jpg\n",
      "ğŸ“„ [70/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0070.jpg\n",
      "ğŸ“„ [71/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0071.jpg\n",
      "ğŸ“„ [72/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0072.jpg\n",
      "ğŸ“„ [73/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0073.jpg\n",
      "ğŸ“„ [74/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0074.jpg\n",
      "ğŸ“„ [75/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0075.jpg\n",
      "ğŸ“„ [76/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0076.jpg\n",
      "ğŸ“„ [77/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0077.jpg\n",
      "ğŸ“„ [78/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0078.jpg\n",
      "ğŸ“„ [79/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0079.jpg\n",
      "ğŸ“„ [80/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0080.jpg\n",
      "ğŸ“„ [81/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0081.jpg\n",
      "ğŸ“„ [82/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0082.jpg\n",
      "ğŸ“„ [83/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0083.jpg\n",
      "ğŸ“„ [84/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0084.jpg\n",
      "ğŸ“„ [85/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0085.jpg\n",
      "ğŸ“„ [86/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0086.jpg\n",
      "ğŸ“„ [87/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0087.jpg\n",
      "ğŸ“„ [88/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0088.jpg\n",
      "ğŸ“„ [89/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0089.jpg\n",
      "ğŸ“„ [90/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0090.jpg\n",
      "ğŸ“„ [91/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0091.jpg\n",
      "ğŸ“„ [92/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0092.jpg\n",
      "ğŸ“„ [93/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0093.jpg\n",
      "ğŸ“„ [94/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0094.jpg\n",
      "ğŸ“„ [95/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0095.jpg\n",
      "ğŸ“„ [96/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0096.jpg\n",
      "ğŸ“„ [97/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0097.jpg\n",
      "ğŸ“„ [98/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0098.jpg\n",
      "ğŸ“„ [99/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0099.jpg\n",
      "ğŸ“„ [100/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0100.jpg\n",
      "ğŸ“„ [101/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0101.jpg\n",
      "ğŸ“„ [102/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0102.jpg\n",
      "ğŸ“„ [103/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0103.jpg\n",
      "ğŸ“„ [104/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0104.jpg\n",
      "ğŸ“„ [105/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0105.jpg\n",
      "ğŸ“„ [106/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0106.jpg\n",
      "ğŸ“„ [107/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0107.jpg\n",
      "ğŸ“„ [108/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0108.jpg\n",
      "ğŸ“„ [109/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0109.jpg\n",
      "ğŸ“„ [110/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0110.jpg\n",
      "ğŸ“„ [111/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0111.jpg\n",
      "ğŸ“„ [112/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0112.jpg\n",
      "ğŸ“„ [113/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0113.jpg\n",
      "ğŸ“„ [114/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0114.jpg\n",
      "ğŸ“„ [115/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0115.jpg\n",
      "ğŸ“„ [116/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0116.jpg\n",
      "ğŸ“„ [117/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0117.jpg\n",
      "ğŸ“„ [118/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0118.jpg\n",
      "ğŸ“„ [119/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0119.jpg\n",
      "ğŸ“„ [120/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0120.jpg\n",
      "ğŸ“„ [121/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0121.jpg\n",
      "ğŸ“„ [122/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0122.jpg\n",
      "ğŸ“„ [123/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0123.jpg\n",
      "ğŸ“„ [124/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0124.jpg\n",
      "ğŸ“„ [125/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0125.jpg\n",
      "ğŸ“„ [126/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0126.jpg\n",
      "ğŸ“„ [127/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0127.jpg\n",
      "ğŸ“„ [128/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0128.jpg\n",
      "ğŸ“„ [129/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0129.jpg\n",
      "ğŸ“„ [130/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0130.jpg\n",
      "ğŸ“„ [131/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0131.jpg\n",
      "ğŸ“„ [132/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0132.jpg\n",
      "ğŸ“„ [133/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0133.jpg\n",
      "ğŸ“„ [134/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0134.jpg\n",
      "ğŸ“„ [135/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0135.jpg\n",
      "ğŸ“„ [136/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0136.jpg\n",
      "ğŸ“„ [137/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0137.jpg\n",
      "ğŸ“„ [138/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0138.jpg\n",
      "ğŸ“„ [139/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0139.jpg\n",
      "ğŸ“„ [140/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0140.jpg\n",
      "ğŸ“„ [141/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0141.jpg\n",
      "ğŸ“„ [142/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0142.jpg\n",
      "ğŸ“„ [143/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0143.jpg\n",
      "ğŸ“„ [144/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0144.jpg\n",
      "ğŸ“„ [145/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0145.jpg\n",
      "ğŸ“„ [146/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0146.jpg\n",
      "ğŸ“„ [147/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0147.jpg\n",
      "ğŸ“„ [148/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0148.jpg\n",
      "ğŸ“„ [149/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0149.jpg\n",
      "ğŸ“„ [150/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0150.jpg\n",
      "ğŸ“„ [151/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0151.jpg\n",
      "ğŸ“„ [152/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0152.jpg\n",
      "ğŸ“„ [153/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0153.jpg\n",
      "ğŸ“„ [154/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0154.jpg\n",
      "ğŸ“„ [155/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0155.jpg\n",
      "ğŸ“„ [156/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0156.jpg\n",
      "ğŸ“„ [157/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0157.jpg\n",
      "ğŸ“„ [158/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0158.jpg\n",
      "ğŸ“„ [159/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0159.jpg\n",
      "ğŸ“„ [160/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0160.jpg\n",
      "ğŸ“„ [161/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0161.jpg\n",
      "ğŸ“„ [162/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0162.jpg\n",
      "ğŸ“„ [163/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0163.jpg\n",
      "ğŸ“„ [164/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0164.jpg\n",
      "ğŸ“„ [165/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0165.jpg\n",
      "ğŸ“„ [166/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0166.jpg\n",
      "ğŸ“„ [167/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0167.jpg\n",
      "ğŸ“„ [168/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0168.jpg\n",
      "ğŸ“„ [169/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0169.jpg\n",
      "ğŸ“„ [170/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0170.jpg\n",
      "ğŸ“„ [171/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0171.jpg\n",
      "ğŸ“„ [172/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0172.jpg\n",
      "ğŸ“„ [173/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0173.jpg\n",
      "ğŸ“„ [174/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0174.jpg\n",
      "ğŸ“„ [175/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0175.jpg\n",
      "ğŸ“„ [176/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0176.jpg\n",
      "ğŸ“„ [177/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0177.jpg\n",
      "ğŸ“„ [178/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0178.jpg\n",
      "ğŸ“„ [179/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0179.jpg\n",
      "ğŸ“„ [180/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0180.jpg\n",
      "ğŸ“„ [181/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0181.jpg\n",
      "ğŸ“„ [182/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0182.jpg\n",
      "ğŸ“„ [183/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0183.jpg\n",
      "ğŸ“„ [184/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0184.jpg\n",
      "ğŸ“„ [185/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0185.jpg\n",
      "ğŸ“„ [186/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0186.jpg\n",
      "ğŸ“„ [187/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0187.jpg\n",
      "ğŸ“„ [188/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0188.jpg\n",
      "ğŸ“„ [189/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0189.jpg\n",
      "ğŸ“„ [190/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0190.jpg\n",
      "ğŸ“„ [191/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0191.jpg\n",
      "ğŸ“„ [192/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0192.jpg\n",
      "ğŸ“„ [193/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0193.jpg\n",
      "ğŸ“„ [194/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0194.jpg\n",
      "ğŸ“„ [195/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0195.jpg\n",
      "ğŸ“„ [196/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0196.jpg\n",
      "ğŸ“„ [197/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0197.jpg\n",
      "ğŸ“„ [198/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0198.jpg\n",
      "ğŸ“„ [199/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0199.jpg\n",
      "ğŸ“„ [200/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0200.jpg\n",
      "ğŸ“„ [201/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0201.jpg\n",
      "ğŸ“„ [202/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0202.jpg\n",
      "ğŸ“„ [203/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0203.jpg\n",
      "ğŸ“„ [204/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0204.jpg\n",
      "ğŸ“„ [205/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0205.jpg\n",
      "ğŸ“„ [206/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0206.jpg\n",
      "ğŸ“„ [207/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0207.jpg\n",
      "ğŸ“„ [208/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0208.jpg\n",
      "ğŸ“„ [209/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0209.jpg\n",
      "ğŸ“„ [210/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0210.jpg\n",
      "ğŸ“„ [211/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0211.jpg\n",
      "ğŸ“„ [212/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0212.jpg\n",
      "ğŸ“„ [213/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0213.jpg\n",
      "ğŸ“„ [214/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0214.jpg\n",
      "ğŸ“„ [215/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0215.jpg\n",
      "ğŸ“„ [216/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0216.jpg\n",
      "ğŸ“„ [217/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0217.jpg\n",
      "ğŸ“„ [218/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0218.jpg\n",
      "ğŸ“„ [219/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0219.jpg\n",
      "ğŸ“„ [220/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0220.jpg\n",
      "ğŸ“„ [221/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0221.jpg\n",
      "ğŸ“„ [222/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0222.jpg\n",
      "ğŸ“„ [223/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0223.jpg\n",
      "ğŸ“„ [224/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0224.jpg\n",
      "ğŸ“„ [225/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0225.jpg\n",
      "ğŸ“„ [226/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0226.jpg\n",
      "ğŸ“„ [227/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0227.jpg\n",
      "ğŸ“„ [228/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0228.jpg\n",
      "ğŸ“„ [229/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0229.jpg\n",
      "ğŸ“„ [230/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0230.jpg\n",
      "ğŸ“„ [231/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0231.jpg\n",
      "ğŸ“„ [232/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0232.jpg\n",
      "ğŸ“„ [233/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0233.jpg\n",
      "ğŸ“„ [234/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0234.jpg\n",
      "ğŸ“„ [235/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0235.jpg\n",
      "ğŸ“„ [236/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0236.jpg\n",
      "ğŸ“„ [237/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0237.jpg\n",
      "ğŸ“„ [238/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0238.jpg\n",
      "ğŸ“„ [239/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0239.jpg\n",
      "ğŸ“„ [240/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0240.jpg\n",
      "ğŸ“„ [241/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0241.jpg\n",
      "ğŸ“„ [242/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0242.jpg\n",
      "ğŸ“„ [243/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0243.jpg\n",
      "ğŸ“„ [244/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0244.jpg\n",
      "ğŸ“„ [245/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0245.jpg\n",
      "ğŸ“„ [246/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0246.jpg\n",
      "ğŸ“„ [247/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0247.jpg\n",
      "ğŸ“„ [248/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0248.jpg\n",
      "ğŸ“„ [249/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0249.jpg\n",
      "ğŸ“„ [250/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0250.jpg\n",
      "ğŸ“„ [251/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0251.jpg\n",
      "ğŸ“„ [252/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0252.jpg\n",
      "ğŸ“„ [253/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0253.jpg\n",
      "ğŸ“„ [254/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0254.jpg\n",
      "ğŸ“„ [255/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0255.jpg\n",
      "ğŸ“„ [256/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0256.jpg\n",
      "ğŸ“„ [257/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0257.jpg\n",
      "ğŸ“„ [258/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0258.jpg\n",
      "ğŸ“„ [259/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0259.jpg\n",
      "ğŸ“„ [260/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0260.jpg\n",
      "ğŸ“„ [261/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0261.jpg\n",
      "ğŸ“„ [262/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0262.jpg\n",
      "ğŸ“„ [263/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0263.jpg\n",
      "ğŸ“„ [264/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0264.jpg\n",
      "ğŸ“„ [265/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0265.jpg\n",
      "ğŸ“„ [266/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0266.jpg\n",
      "ğŸ“„ [267/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0267.jpg\n",
      "ğŸ“„ [268/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0268.jpg\n",
      "ğŸ“„ [269/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0269.jpg\n",
      "ğŸ“„ [270/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0270.jpg\n",
      "ğŸ“„ [271/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0271.jpg\n",
      "ğŸ“„ [272/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0272.jpg\n",
      "ğŸ“„ [273/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0273.jpg\n",
      "ğŸ“„ [274/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0274.jpg\n",
      "ğŸ“„ [275/275] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: 2025-11-04_detail_0275.jpg\n",
      "\n",
      "âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥ OCR à¹à¸¥à¹‰à¸§: C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\\ocr_output_train_CJ.csv\n",
      "ğŸ“Š à¸­à¹ˆà¸²à¸™à¸ªà¸³à¹€à¸£à¹‡à¸ˆ 275/275 à¹„à¸Ÿà¸¥à¹Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "\n",
    "# === CONFIG ===\n",
    "image_folder = r\"C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\"\n",
    "output_csv = os.path.join(image_folder, \"ocr_output_train_CJ.csv\")\n",
    "\n",
    "# === à¸ªà¸£à¹‰à¸²à¸‡ EasyOCR Reader ===\n",
    "reader = easyocr.Reader(['th', 'en'])\n",
    "\n",
    "# === à¹€à¸•à¸£à¸µà¸¢à¸¡à¹„à¸Ÿà¸¥à¹Œà¸ à¸²à¸ ===\n",
    "all_images = sorted([\n",
    "    f for f in os.listdir(image_folder)\n",
    "    if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "])\n",
    "\n",
    "total = len(all_images)\n",
    "ocr_results = []\n",
    "\n",
    "print(f\"ğŸ“‚ à¸à¸šà¸ à¸²à¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” {total} à¹„à¸Ÿà¸¥à¹Œ à¸à¸³à¸¥à¸±à¸‡à¹€à¸£à¸´à¹ˆà¸¡ OCR ...\")\n",
    "\n",
    "# === à¸§à¸™à¸¥à¸¹à¸›à¸—à¸³ OCR à¸—à¸µà¸¥à¸°à¸ à¸²à¸ ===\n",
    "for idx, filename in enumerate(all_images, start=1):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "    print(f\"ğŸ“„ [{idx}/{total}] à¸à¸³à¸¥à¸±à¸‡à¸­à¹ˆà¸²à¸™: {filename}\")\n",
    "\n",
    "    try:\n",
    "        # à¸­à¹ˆà¸²à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸ˆà¸²à¸à¸ à¸²à¸\n",
    "        result = reader.readtext(image_path, detail=0)\n",
    "        combined_text = '|'.join(result).strip()\n",
    "\n",
    "        # à¹€à¸à¸´à¹ˆà¸¡à¹€à¸‚à¹‰à¸² list\n",
    "        ocr_results.append({'filename': filename, 'text': combined_text})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ à¸­à¹ˆà¸²à¸™à¸ à¸²à¸ {filename} à¹„à¸¡à¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {e}\")\n",
    "\n",
    "# === à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥à¹€à¸›à¹‡à¸™ CSV ===\n",
    "df = pd.DataFrame(ocr_results)\n",
    "df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\nâœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸œà¸¥ OCR à¹à¸¥à¹‰à¸§: {output_csv}\")\n",
    "print(f\"ğŸ“Š à¸­à¹ˆà¸²à¸™à¸ªà¸³à¹€à¸£à¹‡à¸ˆ {len(ocr_results)}/{total} à¹„à¸Ÿà¸¥à¹Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d9d21",
   "metadata": {},
   "source": [
    "## LLM gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee1812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ Total images: 275 | To process: 118 | init batch=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/118 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Incomplete batch â†’ shrink batch size to 2 and retry same index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 118/118 [06:39<00:00,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Finished.\n",
      "- JSONL : C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_output_2025-11-04.jsonl\n",
      "- TXT   : C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_txt_2025-11-04\n",
      "- Check : C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_done_list_2025-11-04.txt\n",
      "CSV saved to: C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_output_2025-11-04.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Gemini OCR (VERBATIM) for Jupyter\n",
    "# =========================\n",
    "\n",
    "# !pip -q install google-genai pillow tqdm pandas\n",
    "\n",
    "# ---------- SETTINGS ----------\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”‘ à¹ƒà¸ªà¹ˆ API keys à¸«à¸¥à¸²à¸¢à¸•à¸±à¸§à¹„à¸”à¹‰ (à¹à¸™à¸°à¸™à¸³à¸„à¸™à¸¥à¸°à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸à¸•à¹Œ/à¹‚à¸„à¸§à¸•à¹‰à¸²)\n",
    "KEY_POOL = [\n",
    "    \"Press Key Here\",\n",
    "    \"Press Key Here\",\n",
    "]\n",
    "assert len([k for k in KEY_POOL if k.strip()]) > 0, \"à¸à¸£à¸¸à¸“à¸²à¹ƒà¸ªà¹ˆ API key à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 1 à¸„à¹ˆà¸²\"\n",
    "# ğŸ“ Paths (à¹à¸à¹‰à¹ƒà¸«à¹‰à¸•à¸£à¸‡à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡)\n",
    "INPUT_DIR   = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\")\n",
    "OUT_JSONL   = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_output_2025-11-04.jsonl\")\n",
    "OCR_TXT_DIR = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_txt_2025-11-04\")\n",
    "CHECKPOINT  = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_done_list_2025-11-04.txt\")\n",
    "\n",
    "# âš™ï¸ Config (à¹‚à¸«à¸¡à¸”à¸„à¸´à¸”à¸™à¹‰à¸­à¸¢à¸ªà¸¸à¸”)\n",
    "MODEL             = \"gemini-2.5-flash\"\n",
    "LANG              = \"th\"                 # \"th\" | \"en\"\n",
    "INLINE_LIMIT_MB   = 18.0\n",
    "THINKING_BUDGET   = 0\n",
    "TEMPERATURE       = 0\n",
    "MAX_OUTPUT_TOKENS = 8192\n",
    "INIT_BATCH_SIZE   = 5\n",
    "THROTTLE_SEC      = 1.5\n",
    "MAX_RETRIES       = 8\n",
    "MAX_IMAGES        = 0    # 0=à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”, >0=à¸ˆà¸³à¸à¸±à¸”à¸ˆà¸³à¸™à¸§à¸™à¹€à¸à¸·à¹ˆà¸­à¸—à¸”à¸ªà¸­à¸š\n",
    "EXPORT_CSV        = True\n",
    "\n",
    "# à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ newline à¹ƒà¸™à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: \"keep\" | \"escape\" | \"one_line\"\n",
    "NORMALIZE_TEXT_MODE = \"keep\"\n",
    "\n",
    "# ---------- IMPORTS ----------\n",
    "import io, json, time, re, random\n",
    "from typing import List, Tuple, Any, Dict, Set\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# ---------- FILE UTILS ----------\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
    "\n",
    "def list_images(input_dir: Path) -> List[Path]:\n",
    "    files = []\n",
    "    for ext in IMG_EXTS:\n",
    "        files.extend(sorted(input_dir.rglob(f\"*{ext}\")))\n",
    "    return files\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _infer_mime(suffix: str) -> str:\n",
    "    s = suffix.lower().lstrip(\".\")\n",
    "    return {\"png\":\"image/png\",\"jpg\":\"image/jpeg\",\"jpeg\":\"image/jpeg\",\"webp\":\"image/webp\"}.get(s,\"application/octet-stream\")\n",
    "\n",
    "def use_inline(p: Path, limit_mb=18.0) -> bool:\n",
    "    try:\n",
    "        return (p.stat().st_size / (1024*1024)) <= limit_mb\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "def pillow_or_bytes(p: Path) -> Tuple[Any, bytes]:\n",
    "    with open(p,\"rb\") as f: b=f.read()\n",
    "    im = Image.open(io.BytesIO(b))\n",
    "    return im, b\n",
    "\n",
    "def load_done(path: Path) -> Set[str]:\n",
    "    if not path.exists(): return set()\n",
    "    return {ln.strip() for ln in open(path, encoding=\"utf-8\") if ln.strip()}\n",
    "\n",
    "def append_done(path: Path, names: List[str]):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for n in names: f.write(n+\"\\n\")\n",
    "\n",
    "# ---------- KEY ROTATION ----------\n",
    "class KeyRotator:\n",
    "    def __init__(self, keys: list[str]):\n",
    "        self.keys = [k.strip() for k in keys if k and k.strip()]\n",
    "        if not self.keys:\n",
    "            raise ValueError(\"KEY_POOL is empty\")\n",
    "        self.idx = 0\n",
    "        self._client = None\n",
    "        self._init_client()\n",
    "\n",
    "    @property\n",
    "    def current_key(self) -> str:\n",
    "        return self.keys[self.idx]\n",
    "\n",
    "    def _init_client(self):\n",
    "        os.environ[\"GEMINI_API_KEY\"] = self.current_key\n",
    "        self._client = genai.Client(api_key=self.current_key)\n",
    "\n",
    "    def get_client(self):\n",
    "        return self._client\n",
    "\n",
    "    def rotate(self) -> bool:\n",
    "        nxt = (self.idx + 1) % len(self.keys)\n",
    "        if nxt == self.idx:  # à¸¡à¸µà¸„à¸µà¸¢à¹Œà¹€à¸”à¸µà¸¢à¸§\n",
    "            return False\n",
    "        self.idx = nxt\n",
    "        print(f\"ğŸ”‘ Switching API key â†’ {self.idx+1}/{len(self.keys)}\")\n",
    "        self._init_client()\n",
    "        return True\n",
    "\n",
    "rotator = KeyRotator(KEY_POOL)\n",
    "def build_client() -> \"genai.Client\":\n",
    "    return rotator.get_client()\n",
    "\n",
    "# ---------- JSON PARSER (à¸—à¸™à¸—à¸²à¸™) ----------\n",
    "CONTROL_CHARS_RE = re.compile(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]')\n",
    "\n",
    "def safe_json_array_parse(text: str) -> list[dict]:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        raise json.JSONDecodeError(\"Empty response\", \"\", 0)\n",
    "\n",
    "    if \"```\" in text:\n",
    "        text = max(text.split(\"```\"), key=len)\n",
    "\n",
    "    text = CONTROL_CHARS_RE.sub(\"\", text).strip()\n",
    "\n",
    "    # 1) à¸—à¸±à¹‰à¸‡à¸à¹‰à¸­à¸™\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, list): return obj\n",
    "    except: pass\n",
    "\n",
    "    # 2) à¸”à¸¶à¸‡à¸šà¸¥à¹‡à¸­à¸ [ ... ]\n",
    "    m = re.search(r'\\[\\s*{.*}\\s*\\]', text, flags=re.DOTALL)\n",
    "    if m:\n",
    "        try:\n",
    "            obj = json.loads(m.group(0))\n",
    "            if isinstance(obj, list): return obj\n",
    "        except: pass\n",
    "\n",
    "    # 3) Fallback JSONL\n",
    "    arr = []\n",
    "    for line in text.splitlines():\n",
    "        line = CONTROL_CHARS_RE.sub(\"\", line.strip().strip(\"`\"))\n",
    "        if not line or not (line.startswith(\"{\") and line.endswith(\"}\")):\n",
    "            continue\n",
    "        try:\n",
    "            arr.append(json.loads(line))\n",
    "        except: \n",
    "            continue\n",
    "    if arr: return arr\n",
    "\n",
    "    raise json.JSONDecodeError(\"Unable to parse JSON array from model output\", text[:200] + \"...\", 0)\n",
    "\n",
    "# ---------- PROMPTS (VERBATIM) ----------\n",
    "def single_image_prompt(lang: str) -> str:\n",
    "    if lang == \"th\":\n",
    "        return (\n",
    "            \"à¹‚à¸«à¸¡à¸” VERBATIM OCR:\\n\"\n",
    "            \"- à¸–à¸­à¸”à¹€à¸‰à¸à¸²à¸°à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¸ˆà¸²à¸à¸ à¸²à¸à¹à¸šà¸šà¸•à¸£à¸‡à¸•à¸±à¸§à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\\n\"\n",
    "            \"- à¸«à¹‰à¸²à¸¡à¹à¸›à¸¥ à¸«à¹‰à¸²à¸¡à¹€à¸”à¸² à¸«à¹‰à¸²à¸¡à¹€à¸•à¸´à¸¡à¸„à¸³ à¸«à¹‰à¸²à¸¡à¹à¸à¹‰à¸ªà¸°à¸à¸” à¸«à¹‰à¸²à¸¡à¸ªà¸£à¸¸à¸› à¸«à¹‰à¸²à¸¡à¹€à¸£à¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ\\n\"\n",
    "            \"- à¸„à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸¥à¸°à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¹ƒà¸™à¸ à¸²à¸\\n\"\n",
    "            \"- à¹€à¸à¹‡à¸šà¸•à¸±à¸§à¹€à¸¥à¸‚ à¸ªà¸±à¸à¸¥à¸±à¸à¸©à¸“à¹Œ à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡à¸«à¸¡à¸²à¸¢ à¸—à¸¸à¸à¸•à¸±à¸§à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™\\n\"\n",
    "            \"- à¸–à¹‰à¸²à¸­à¹ˆà¸²à¸™à¹„à¸¡à¹ˆà¸Šà¸±à¸” à¹ƒà¸«à¹‰à¸à¸´à¸¡à¸à¹Œ 'ï¿½' à¹à¸—à¸™ à¸«à¹‰à¸²à¸¡à¹€à¸”à¸²\\n\"\n",
    "            \"- à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸¥à¹‰à¸§à¸™ (plain text) à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            \"VERBATIM OCR mode:\\n\"\n",
    "            \"- Transcribe ONLY characters visible in the image.\\n\"\n",
    "            \"- No translation, inference, normalization, correction, summarization, or reordering.\\n\"\n",
    "            \"- Preserve line breaks and spacing exactly.\\n\"\n",
    "            \"- Keep digits and symbols exactly as seen.\\n\"\n",
    "            \"- If unreadable, output 'ï¿½' (do not guess).\\n\"\n",
    "            \"- Output plain text only.\"\n",
    "        )\n",
    "\n",
    "def make_batch_prompt_json_array(lang: str, filenames: list[str]) -> str:\n",
    "    names = \"\\n\".join(filenames)\n",
    "    n = len(filenames)\n",
    "    if lang == \"th\":\n",
    "        return (\n",
    "            \"à¹‚à¸«à¸¡à¸” VERBATIM OCR (à¸«à¸¥à¸²à¸¢à¹„à¸Ÿà¸¥à¹Œ):\\n\"\n",
    "            \"- à¸–à¸­à¸”à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸•à¸£à¸‡à¸•à¸±à¸§à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹à¸›à¸¥/à¹€à¸”à¸²/à¹€à¸•à¸´à¸¡/à¹à¸à¹‰/à¸ªà¸£à¸¸à¸›/à¸ˆà¸±à¸”à¸£à¸¹à¸›\\n\"\n",
    "            \"- à¸„à¸‡à¸šà¸£à¸£à¸—à¸±à¸”à¹à¸¥à¸°à¸Šà¹ˆà¸­à¸‡à¸§à¹ˆà¸²à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¹ƒà¸™à¸ à¸²à¸\\n\"\n",
    "            \"- à¸•à¸±à¸§à¸­à¹ˆà¸²à¸™à¹„à¸¡à¹ˆà¸Šà¸±à¸”à¹ƒà¸«à¹‰à¹ƒà¸ªà¹ˆ 'ï¿½'\\n\"\n",
    "            f\"- à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ **JSON Array à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™** à¸ˆà¸³à¸™à¸§à¸™ {n} à¸Šà¸´à¹‰à¸™ à¹€à¸£à¸µà¸¢à¸‡à¸•à¸²à¸¡à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸”à¹‰à¸²à¸™à¸¥à¹ˆà¸²à¸‡\\n\"\n",
    "            'à¸£à¸¹à¸›à¹à¸šà¸š: [{\"image\":\"<filename>\",\"text\":\"<verbatim-text>\"} , ...]\\n'\n",
    "            \"à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸š:\\n\" + names + \"\\n\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            \"VERBATIM OCR (multi-file):\\n\"\n",
    "            \"- Transcribe exactly; no translation/inference/correction/summarization/reformatting.\\n\"\n",
    "            \"- Preserve line breaks and spacing.\\n\"\n",
    "            \"- Use 'ï¿½' where unreadable.\\n\"\n",
    "            f\"- Reply as **JSON Array only**, length={n}, in the same order below:\\n\"\n",
    "            '[{\"image\":\"<filename>\",\"text\":\"<verbatim-text>\"} , ...]\\n'\n",
    "            \"Filenames:\\n\" + names + \"\\n\"\n",
    "        )\n",
    "\n",
    "# ---------- MODEL CALLS ----------\n",
    "from google.genai import types\n",
    "\n",
    "def call_batch_json_array(client: \"genai.Client\", model: str, parts: list,\n",
    "                          thinking_budget: int, max_output_tokens: int, temperature: float) -> str:\n",
    "    cfg = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget),\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        response_mime_type=\"application/json\",\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    resp = client.models.generate_content(model=model, contents=parts, config=cfg)\n",
    "    return (resp.text or \"\").strip()\n",
    "\n",
    "def process_batch_json_array(client: \"genai.Client\", model: str, batch_imgs: list[Path], lang: str,\n",
    "                             inline_limit_mb: float, thinking_budget: int, max_output_tokens: int, temperature: float) -> tuple[list[dict], bool]:\n",
    "    filenames = [p.name for p in batch_imgs]\n",
    "    prompt = make_batch_prompt_json_array(lang, filenames)\n",
    "\n",
    "    parts = [prompt]\n",
    "    for p in batch_imgs:\n",
    "        if use_inline(p, inline_limit_mb):\n",
    "            _, b = pillow_or_bytes(p)\n",
    "            parts.append(types.Part.from_bytes(data=b, mime_type=_infer_mime(p.suffix)))\n",
    "        else:\n",
    "            up = client.files.upload(file=str(p))\n",
    "            parts.append(up)\n",
    "\n",
    "    raw = call_batch_json_array(client, model, parts, thinking_budget, max_output_tokens, temperature)\n",
    "\n",
    "    try:\n",
    "        arr = safe_json_array_parse(raw)\n",
    "        by_name = { (item.get(\"image\") or \"\").strip(): (item.get(\"text\") or \"\") for item in arr if isinstance(item, dict) }\n",
    "        ordered = [ {\"image\": fn, \"text\": by_name.get(fn, \"\")} for fn in filenames ]\n",
    "        ok = len(ordered) == len(filenames) and all(ordered[i][\"image\"] == filenames[i] for i in range(len(filenames)))\n",
    "        return ordered, ok\n",
    "    except Exception:\n",
    "        try:\n",
    "            log_dir = Path(\"./_gemini_raw\"); log_dir.mkdir(exist_ok=True)\n",
    "            ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            (log_dir / f\"batch_parse_error_{ts}.txt\").write_text(raw, encoding=\"utf-8\")\n",
    "        except:\n",
    "            pass\n",
    "        ordered = [ {\"image\": fn, \"text\": \"\"} for fn in filenames ]\n",
    "        return ordered, False\n",
    "\n",
    "def process_single_image(client: \"genai.Client\", model: str, p: Path, lang: str,\n",
    "                         inline_limit_mb: float, thinking_budget: int, max_output_tokens: int, temperature: float) -> str:\n",
    "    prompt = single_image_prompt(lang)\n",
    "    if use_inline(p, inline_limit_mb):\n",
    "        _, b = pillow_or_bytes(p)\n",
    "        image_part = types.Part.from_bytes(data=b, mime_type=_infer_mime(p.suffix))\n",
    "    else:\n",
    "        image_part = client.files.upload(file=str(p))\n",
    "    cfg = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget),\n",
    "        max_output_tokens=max_output_tokens,\n",
    "        response_mime_type=\"text/plain\",\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    resp = client.models.generate_content(model=model, contents=[prompt, image_part], config=cfg)\n",
    "    return (resp.text or \"\").strip()\n",
    "\n",
    "# ---------- ERROR HELPERS ----------\n",
    "def _is_quota_or_rate_error(msg: str) -> bool:\n",
    "    msg = (msg or \"\").lower()\n",
    "    needles = [\"429\", \"quota\", \"rate\", \"too many requests\", \"exceeded\", \"resourceexhausted\"]\n",
    "    return any(n in msg for n in needles)\n",
    "\n",
    "def _is_transient_server_error(msg: str) -> bool:\n",
    "    msg = (msg or \"\").lower()\n",
    "    needles = [\"503\", \"unavailable\", \"internal\", \"5xx\", \"server error\",\n",
    "               \"deadline\", \"gateway\", \"temporarily\", \"upstream\", \"rst\"]\n",
    "    return any(n in msg for n in needles)\n",
    "\n",
    "# ---------- SAFE WRAPPERS ----------\n",
    "def safe_process_batch_json_array(*args, max_retries=MAX_RETRIES, throttle_sec=THROTTLE_SEC, **kwargs):\n",
    "    base_delay = float(throttle_sec) if throttle_sec else 0.0\n",
    "    delay = base_delay\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if attempt == 0 and delay > 0:\n",
    "                time.sleep(delay)\n",
    "            return process_batch_json_array(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            if _is_quota_or_rate_error(msg):\n",
    "                switched = rotator.rotate()\n",
    "                if not switched:\n",
    "                    delay = min(max(5.0, (delay or 2.0) * 1.8), 180.0)\n",
    "                else:\n",
    "                    delay = 1.0\n",
    "                time.sleep(delay + random.uniform(0, 0.7))\n",
    "                continue\n",
    "            if _is_transient_server_error(msg):\n",
    "                delay = min(max(4.0, (delay or 2.0) * 1.6), 180.0)\n",
    "                time.sleep(delay + random.uniform(0, 1.2))\n",
    "                continue\n",
    "            raise\n",
    "    return [], False\n",
    "\n",
    "def safe_process_single_image(p: Path, max_retries=MAX_RETRIES) -> str:\n",
    "    delay = 1.0\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return process_single_image(\n",
    "                build_client(), MODEL, p, LANG,\n",
    "                INLINE_LIMIT_MB, THINKING_BUDGET, MAX_OUTPUT_TOKENS, TEMPERATURE\n",
    "            )\n",
    "        except Exception as e:\n",
    "            msg = str(e)\n",
    "            if _is_quota_or_rate_error(msg):\n",
    "                switched = rotator.rotate()\n",
    "                if not switched:\n",
    "                    delay = min(max(5.0, delay * 1.8), 180.0)\n",
    "                else:\n",
    "                    delay = 1.0\n",
    "                time.sleep(delay + random.uniform(0, 0.7))\n",
    "                continue\n",
    "            if _is_transient_server_error(msg):\n",
    "                delay = min(max(3.0, delay * 1.6), 180.0)\n",
    "                time.sleep(delay + random.uniform(0, 1.0))\n",
    "                continue\n",
    "            raise\n",
    "    return \"\"\n",
    "\n",
    "# ---------- NORMALIZE NEWLINES ----------\n",
    "def normalize_text_newlines(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    if NORMALIZE_TEXT_MODE == \"keep\":\n",
    "        return s\n",
    "    elif NORMALIZE_TEXT_MODE == \"escape\":\n",
    "        return s.replace(\"\\n\", \"\\\\n\")\n",
    "    elif NORMALIZE_TEXT_MODE == \"one_line\":\n",
    "        return \" \".join(s.splitlines())\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# ---------- RUNNER ----------\n",
    "ensure_dir(OCR_TXT_DIR)\n",
    "\n",
    "done_set = load_done(CHECKPOINT)\n",
    "\n",
    "images_all = list_images(INPUT_DIR)\n",
    "images = [p for p in images_all if p.name not in done_set]\n",
    "if MAX_IMAGES and MAX_IMAGES > 0:\n",
    "    images = images[:MAX_IMAGES]\n",
    "\n",
    "print(f\"â–¶ï¸ Total images: {len(images_all)} | To process: {len(images)} | init batch={INIT_BATCH_SIZE}\")\n",
    "\n",
    "def write_result_record(jsonl_f, p: Path, txt: str):\n",
    "    txt_norm = normalize_text_newlines(txt)\n",
    "    (OCR_TXT_DIR/p.stem).with_suffix(\".txt\").write_text(txt_norm, encoding=\"utf-8\")\n",
    "    jsonl_f.write(json.dumps({\"image\": str(p), \"text\": txt_norm}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def run_adaptive(images: List[Path], init_bs: int):\n",
    "    bs = max(1, int(init_bs))\n",
    "    i = 0\n",
    "    failed_names = []\n",
    "    with open(OUT_JSONL, \"a\", encoding=\"utf-8\") as f_jsonl:\n",
    "        pbar = tqdm(total=len(images))\n",
    "        while i < len(images):\n",
    "            batch = images[i:i+bs]\n",
    "\n",
    "            arr, ok = safe_process_batch_json_array(\n",
    "                build_client(), MODEL, batch, LANG,\n",
    "                INLINE_LIMIT_MB, THINKING_BUDGET, MAX_OUTPUT_TOKENS, TEMPERATURE,\n",
    "                max_retries=MAX_RETRIES, throttle_sec=THROTTLE_SEC\n",
    "            )\n",
    "\n",
    "            if not ok and bs > 1:\n",
    "                bs = max(1, bs // 2)\n",
    "                print(f\"âš ï¸ Incomplete batch â†’ shrink batch size to {bs} and retry same index\")\n",
    "                time.sleep(3)\n",
    "                continue\n",
    "\n",
    "            if not ok and bs == 1:\n",
    "                p = batch[0]\n",
    "                try:\n",
    "                    txt = safe_process_single_image(p, max_retries=MAX_RETRIES)\n",
    "                except Exception:\n",
    "                    txt = \"\"\n",
    "                    failed_names.append(p.name)\n",
    "\n",
    "                write_result_record(f_jsonl, p, txt)\n",
    "                append_done(CHECKPOINT, [p.name])\n",
    "                i += 1\n",
    "                pbar.update(1)\n",
    "                bs = min(init_bs, bs + 1)\n",
    "                continue\n",
    "\n",
    "            by_name = { r.get(\"image\",\"\"): r.get(\"text\",\"\") for r in arr }\n",
    "            just_done = []\n",
    "            for p in batch:\n",
    "                txt = by_name.get(p.name, \"\")\n",
    "                if not isinstance(txt, str):\n",
    "                    txt = \"\"\n",
    "                    failed_names.append(p.name)\n",
    "                write_result_record(f_jsonl, p, txt)\n",
    "                just_done.append(p.name)\n",
    "\n",
    "            append_done(CHECKPOINT, just_done)\n",
    "            i += len(batch)\n",
    "            pbar.update(len(batch))\n",
    "        pbar.close()\n",
    "    return failed_names\n",
    "\n",
    "failed = run_adaptive(images, INIT_BATCH_SIZE)\n",
    "\n",
    "print(f\"\\nâœ… Finished.\\n- JSONL : {OUT_JSONL}\\n- TXT   : {OCR_TXT_DIR}\\n- Check : {CHECKPOINT}\")\n",
    "if failed:\n",
    "    print(f\"âš ï¸ {len(failed)} file(s) ended up with empty text (kept as ''). You can re-run those.\")\n",
    "\n",
    "# ---------- EXPORT CSV ----------\n",
    "if EXPORT_CSV:\n",
    "    import csv\n",
    "    rows = []\n",
    "    if OUT_JSONL.exists():\n",
    "        with open(OUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "            for ln in f:\n",
    "                ln = ln.strip()\n",
    "                if not ln: \n",
    "                    continue\n",
    "                try:\n",
    "                    obj = json.loads(ln)\n",
    "                    rows.append(obj)\n",
    "                except:\n",
    "                    pass\n",
    "    df = pd.DataFrame(rows)\n",
    "    csv_path = OUT_JSONL.with_suffix(\".csv\")\n",
    "    df.to_csv(csv_path,\n",
    "              index=False,\n",
    "              encoding=\"utf-8-sig\",\n",
    "              quoting=csv.QUOTE_ALL,\n",
    "              lineterminator=\"\\n\")\n",
    "    print(\"CSV saved to:\", csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6b2cf3",
   "metadata": {},
   "source": [
    "## LLM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af539f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Easy CSV keys (raw): 275\n",
      "ğŸ“„ LLM CSV keys (raw): 275\n",
      "ğŸ§® Images (unique, resolved): 275\n",
      "Token-by-Token pick (batch):  24%|â–ˆâ–ˆâ–       | 66/275 [06:51<20:48,  5.97s/it]ğŸ”‘ Switch API key â†’ 2/7\n",
      "Token-by-Token pick (batch):  34%|â–ˆâ–ˆâ–ˆâ–      | 94/275 [08:53<08:58,  2.97s/it]ğŸ”‘ Switch API key â†’ 3/7\n",
      "ğŸ”‘ Switch API key â†’ 4/7\n",
      "ğŸ”‘ Switch API key â†’ 5/7\n",
      "Token-by-Token pick (batch):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 103/275 [09:35<13:43,  4.79s/it]ğŸ”‘ Switch API key â†’ 6/7\n",
      "Token-by-Token pick (batch):  40%|â–ˆâ–ˆâ–ˆâ–‰      | 109/275 [10:01<11:08,  4.03s/it]ğŸ”‘ Switch API key â†’ 7/7\n",
      "Token-by-Token pick (batch):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 112/275 [10:24<15:42,  5.78s/it]ğŸ”‘ Switch API key â†’ 1/7\n",
      "Token-by-Token pick (batch):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 148/275 [14:57<11:46,  5.56s/it]ğŸ”‘ Switch API key â†’ 2/7\n",
      "ğŸ”‘ Switch API key â†’ 3/7\n",
      "ğŸ”‘ Switch API key â†’ 4/7\n",
      "Token-by-Token pick (batch):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 234/275 [23:59<03:25,  5.01s/it]ğŸ”‘ Switch API key â†’ 5/7\n",
      "ğŸ”‘ Switch API key â†’ 6/7\n",
      "ğŸ”‘ Switch API key â†’ 7/7\n",
      "Token-by-Token pick (batch):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 273/275 [28:10<00:08,  4.46s/it]ğŸ”‘ Switch API key â†’ 1/7\n",
      "ğŸ”‘ Switch API key â†’ 2/7\n",
      "Token-by-Token pick (batch): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 275/275 [28:25<00:00,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "JSONL: C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\LLM_data-correction\\fulltext_pick_2025-11-04.jsonl\n",
      "CSV  : C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\LLM_data-correction\\fulltext_pick_2025-11-04.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\orawanya Eve\\AppData\\Local\\Temp\\ipykernel_20036\\2360506313.py:810: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(to_one_line)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ===========================================================\n",
    "# Thai Full-Image Text Correction (Token-by-Token, Batch + OCR fallback)\n",
    "# - à¹€à¸¥à¸·à¸­à¸à¸„à¸³à¸•à¹ˆà¸­à¸„à¸³à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ EasyOCR à¸à¸±à¸š LLM-OCR à¸”à¹‰à¸§à¸¢à¸ à¸²à¸à¸ˆà¸£à¸´à¸‡à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸\n",
    "# - à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸³à¹„à¸«à¸™à¸ˆà¸²à¸ CSV à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸ à¸²à¸ â†’ OCR à¸„à¸³à¹ƒà¸«à¸¡à¹ˆ (fallback)\n",
    "# - Batch à¸«à¸¥à¸²à¸¢à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¹ƒà¸™à¸„à¸£à¸±à¹‰à¸‡à¹€à¸”à¸µà¸¢à¸§ à¹€à¸à¸·à¹ˆà¸­à¸¥à¸”à¹€à¸§à¸¥à¸²/à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢\n",
    "# - Output:\n",
    "#   CSV   => (à¸‚à¸¶à¹‰à¸™à¸à¸±à¸š ONLY_PRODUCT_NAME) image, product_name[, text_full, text_llm_only]\n",
    "#   JSONL => à¹€à¸à¹‡à¸šà¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸²à¸£à¸•à¸±à¸”à¸ªà¸´à¸™à¹ƒà¸ˆà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” (à¸•à¹ˆà¸­à¸ à¸²à¸)\n",
    "# - à¸—à¸¸à¸à¸Ÿà¸´à¸¥à¸”à¹Œà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸šà¸µà¸šà¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ \"à¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸”à¸µà¸¢à¸§\" à¹€à¸ªà¸¡à¸­\n",
    "# ===========================================================\n",
    "# pip install -q google-genai pillow pandas tqdm\n",
    "# (optional): pip install pythainlp regex rapidfuzz\n",
    "\n",
    "from pathlib import Path\n",
    "import os, re, json, time, random, tempfile, sys, difflib\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "# --- API Keys ---\n",
    "KEY_POOL = [\n",
    "    \"Press Key Here\",\n",
    "    \"Press Key Here\",\n",
    "]\n",
    "assert len([k for k in KEY_POOL if k.strip()]) > 0, \"à¸à¸£à¸¸à¸“à¸²à¹ƒà¸ªà¹ˆ API key à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 1 à¸„à¹ˆà¸²\"\n",
    "\n",
    "# --- Inputs (à¸›à¸£à¸±à¸šà¸•à¸²à¸¡à¹„à¸Ÿà¸¥à¹Œà¸‚à¸­à¸‡à¸„à¸¸à¸“) ---\n",
    "CSV_FILES = [\n",
    "    (\"Easy\", r\"C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\\ocr_output_train_CJ.csv\"),\n",
    "    (\"LLM\",  r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\ocr_output_2025-11-04.csv\"),\n",
    "]\n",
    "IMAGE_ROOT = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\")\n",
    "\n",
    "# --- Outputs ---\n",
    "OUT_JSONL = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\LLM_data-correction\\fulltext_pick_2025-11-04.jsonl\")\n",
    "OUT_CSV   = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\OCR_LLM\\LLM_data-correction\\fulltext_pick_2025-11-04.csv\")\n",
    "\n",
    "# --- Export mode ---\n",
    "ONLY_PRODUCT_NAME = True   # True = CSV à¸ˆà¸°à¸¡à¸µà¹à¸„à¹ˆ image, product_name | False = à¸šà¸§à¸ text_full, text_llm_only\n",
    "\n",
    "# --- Model config ---\n",
    "MODEL              = \"gemini-2.5-flash\"\n",
    "TEMPERATURE        = 0.05\n",
    "TOP_P              = 0.2\n",
    "TOP_K              = 1\n",
    "THINKING_BUDGET    = 0\n",
    "INLINE_LIMIT_MB    = 2.0\n",
    "MAX_OUTPUT_TOKENS  = 192\n",
    "THROTTLE_SEC       = 0.4\n",
    "MAX_RETRIES        = 3\n",
    "\n",
    "RUN_ID             = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "MAX_SIDE           = 1280\n",
    "JPEG_QUALITY       = 75\n",
    "\n",
    "MAX_CANDIDATES_PER_POS = 3\n",
    "USE_BATCH          = True\n",
    "BATCH_POS          = 24\n",
    "\n",
    "# ===================== Optional libs =====================\n",
    "try:\n",
    "    from pythainlp import word_tokenize as th_word_tokenize\n",
    "except Exception:\n",
    "    th_word_tokenize = None\n",
    "\n",
    "try:\n",
    "    import regex as re_grx\n",
    "except Exception:\n",
    "    re_grx = None\n",
    "\n",
    "try:\n",
    "    from rapidfuzz.distance import Levenshtein\n",
    "except Exception:\n",
    "    Levenshtein = None\n",
    "\n",
    "# ===================== Utils =====================\n",
    "def log(*args): print(*args, file=sys.stderr)\n",
    "\n",
    "CONTROL_RE = re.compile(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]')\n",
    "THAI_UNIT_TOKENS = [\"à¸¡à¸¥.\",\"à¸¥à¸´à¸•à¸£\",\"à¸à¸£à¸±à¸¡\",\"à¸.\",\"à¸à¸.\",\"à¸‚à¸§à¸”\",\"à¸‹à¸­à¸‡\",\"à¸à¸¥à¹ˆà¸­à¸‡\",\"à¹à¸à¹‡à¸„\",\"à¹à¸à¸„\",\"à¹à¸à¹‡à¸„à¸„à¸¹à¹ˆ\",\"à¸Šà¸´à¹‰à¸™\",\"à¹à¸œà¸‡\",\"à¸Šà¸¸à¸”\",\"à¹à¸šà¸š\",\"à¹„à¸‹à¸ªà¹Œ\",\"à¹„à¸‹à¸‹à¹Œ\",\"à¸–à¸¸à¸‡\",\"à¸‚à¸™à¸±à¸”\"]\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def clear_outputs():\n",
    "    for p in [OUT_JSONL, OUT_CSV]:\n",
    "        try:\n",
    "            if p.exists(): p.unlink()\n",
    "        except: pass\n",
    "\n",
    "def to_one_line(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "def try_read_csv(path: Path) -> Optional[pd.DataFrame]:\n",
    "    if not path or not Path(path).exists():\n",
    "        log(f\"âš ï¸ CSV not found: {path}\")\n",
    "        return None\n",
    "    for enc in [\"utf-8-sig\", \"utf-8\", \"cp874\", \"cp1252\", \"latin1\"]:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        return pd.read_csv(path, engine=\"python\")\n",
    "    except Exception as e:\n",
    "        log(f\"âŒ cannot read CSV: {path} -> {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------- Client with key rotation ----------\n",
    "class KeyRotator:\n",
    "    def __init__(self, keys: List[str]):\n",
    "        ks = [k.strip() for k in keys if k and k.strip()]\n",
    "        if not ks: raise ValueError(\"KEY_POOL is empty\")\n",
    "        self.keys = ks\n",
    "        self.idx = 0\n",
    "        self._client = None\n",
    "        self._init_client()\n",
    "\n",
    "    def _init_client(self):\n",
    "        os.environ[\"GEMINI_API_KEY\"] = self.keys[self.idx]\n",
    "        self._client = genai.Client(api_key=self.keys[self.idx])\n",
    "\n",
    "    def client(self) -> \"genai.Client\":\n",
    "        return self._client\n",
    "\n",
    "    def rotate(self) -> bool:\n",
    "        if len(self.keys) == 1:\n",
    "            time.sleep(1.0)\n",
    "            return False\n",
    "        self.idx = (self.idx + 1) % len(self.keys)\n",
    "        log(f\"ğŸ”‘ Switch API key â†’ {self.idx+1}/{len(self.keys)}\")\n",
    "        self._init_client()\n",
    "        return True\n",
    "\n",
    "rotator = KeyRotator(KEY_POOL)\n",
    "def build_client() -> \"genai.Client\":\n",
    "    return rotator.client()\n",
    "\n",
    "# ---------- Image helper ----------\n",
    "def _infer_mime(suffix: str) -> str:\n",
    "    s = suffix.lower().lstrip(\".\")\n",
    "    return {\"png\":\"image/png\",\"jpg\":\"image/jpeg\",\"jpeg\":\"image/jpeg\",\"webp\":\"image/webp\"}.get(s,\"application/octet-stream\")\n",
    "\n",
    "def to_bytes(p: Path) -> bytes:\n",
    "    with open(p, \"rb\") as f: return f.read()\n",
    "\n",
    "def prepare_image_for_upload(p: Path) -> Path:\n",
    "    try:\n",
    "        im = Image.open(p).convert(\"RGB\")\n",
    "        w, h = im.size\n",
    "        scale = min(1.0, MAX_SIDE / max(w, h))\n",
    "        if scale < 1.0:\n",
    "            im = im.resize((max(1,int(w*scale)), max(1,int(h*scale))), Image.LANCZOS)\n",
    "        tmp = Path(tempfile.gettempdir()) / f\"llm_img_{p.stem}_{im.size[0]}x{im.size[1]}.jpg\"\n",
    "        im.save(tmp, format=\"JPEG\", quality=JPEG_QUALITY, optimize=True)\n",
    "        return tmp\n",
    "    except Exception as e:\n",
    "        log(f\"âš ï¸ prepare_image_for_upload failed ({p}): {e}\")\n",
    "        return p\n",
    "\n",
    "def make_image_part(p: Path) -> Any:\n",
    "    client = build_client()\n",
    "    try:\n",
    "        size_mb = p.stat().st_size / (1024*1024)\n",
    "    except:\n",
    "        size_mb = INLINE_LIMIT_MB + 1.0\n",
    "    if size_mb <= INLINE_LIMIT_MB:\n",
    "        try:\n",
    "            return types.Part.from_bytes(data=to_bytes(p), mime_type=_infer_mime(p.suffix))\n",
    "        except Exception as e:\n",
    "            log(f\"âš ï¸ inline image failed, will upload: {e}\")\n",
    "    up = prepare_image_for_upload(p)\n",
    "    try:\n",
    "        return client.files.upload(file=str(up))\n",
    "    except Exception as e:\n",
    "        log(f\"âŒ image upload failed ({p}): {e}\")\n",
    "        try:\n",
    "            return types.Part.from_bytes(data=to_bytes(up), mime_type=_infer_mime(up.suffix))\n",
    "        except:\n",
    "            return types.Part.from_bytes(data=b\"\", mime_type=\"application/octet-stream\")\n",
    "\n",
    "IMAGE_PART_CACHE: Dict[str, Any] = {}\n",
    "def get_image_part_for(p: Path):\n",
    "    key = str(p.resolve())\n",
    "    if key not in IMAGE_PART_CACHE:\n",
    "        IMAGE_PART_CACHE[key] = make_image_part(p)\n",
    "    return IMAGE_PART_CACHE[key]\n",
    "\n",
    "# ---------- Image index / resolve ----------\n",
    "def index_images(root: Path, exts=(\".png\",\".jpg\",\".jpeg\",\".webp\")) -> Dict[str, List[Path]]:\n",
    "    idx: Dict[str, List[Path]] = {}\n",
    "    if root and root.exists():\n",
    "        for p in root.rglob(\"*\"):\n",
    "            if p.suffix.lower() in exts and p.is_file():\n",
    "                idx.setdefault(p.name.lower(), []).append(p.resolve())\n",
    "    return idx\n",
    "\n",
    "IMAGE_INDEX = {}\n",
    "def resolve_image_path(img_str: str) -> Optional[Path]:\n",
    "    s = str(img_str).strip().strip('\"').strip(\"'\")\n",
    "    if not s: return None\n",
    "    p = Path(s)\n",
    "    if p.is_absolute() and p.exists(): return p.resolve()\n",
    "    if (Path.cwd() / p).exists(): return (Path.cwd() / p).resolve()\n",
    "    if IMAGE_ROOT and (IMAGE_ROOT / p).exists(): return (IMAGE_ROOT / p).resolve()\n",
    "    base = Path(s).name.lower()\n",
    "    cands = IMAGE_INDEX.get(base, [])\n",
    "    if cands:\n",
    "        try:\n",
    "            root_s = str(IMAGE_ROOT.resolve()).lower()\n",
    "            prefer = [c for c in cands if str(c).lower().startswith(root_s)]\n",
    "            return prefer[0] if prefer else cands[0]\n",
    "        except:\n",
    "            return cands[0]\n",
    "    return None\n",
    "\n",
    "# ---------- Text normalize / tokenize ----------\n",
    "def clean_for_all_text(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    t = str(s)\n",
    "    t = re.sub(r\"^\\s*\\d+\\s*[\\.\\)\\-:]\\s*\", \"\", t.strip())\n",
    "    t = CONTROL_RE.sub(\"\", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def tokenize_all_text(text: str) -> List[str]:\n",
    "    t = clean_for_all_text(text or \"\")\n",
    "    if not t: return []\n",
    "    if th_word_tokenize:\n",
    "        try:\n",
    "            toks = [w.strip() for w in th_word_tokenize(t, engine=\"newmm\") if w.strip()]\n",
    "        except Exception:\n",
    "            toks = [w for w in re.split(r\"[ \\t\\n\\r\\f\\v/|]+\", t) if w]\n",
    "    else:\n",
    "        toks = [w for w in re.split(r\"[ \\t\\n\\r\\f\\v/|]+\", t) if w]\n",
    "    return toks\n",
    "\n",
    "def join_tokens_all(tokens: List[str]) -> str:\n",
    "    s = \" \".join([t for t in tokens if t]).strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# ---------- CSV loader & collect text ----------\n",
    "def load_rows(csv_path: Path) -> Dict[str, dict]:\n",
    "    df = try_read_csv(csv_path)\n",
    "    if df is None or df.empty:\n",
    "        return {}\n",
    "    image_col = None\n",
    "    for c in df.columns:\n",
    "        if str(c).lower() in [\"image\",\"img\",\"image_path\",\"filename\",\"file\",\"path\"]:\n",
    "            image_col = c; break\n",
    "    if image_col is None:\n",
    "        image_col = df.columns[0]\n",
    "        log(f\"âš ï¸ 'image' column not found in {csv_path.name}. Using first column: {image_col}\")\n",
    "    out = {}\n",
    "    for _, r in df.iterrows():\n",
    "        img = str(r.get(image_col, \"\") if pd.notna(r.get(image_col, \"\")) else \"\").strip()\n",
    "        if not img: continue\n",
    "        row = {}\n",
    "        for c in df.columns:\n",
    "            v = r.get(c)\n",
    "            row[c] = v\n",
    "            row[str(c).lower()] = v\n",
    "        out[img] = row\n",
    "    return out\n",
    "\n",
    "POSSIBLE_TEXT_COLS = [\"text\",\"product_name\",\"name\",\"title\",\"desc\",\"description\",\"ocr_text\",\"full_text\"]\n",
    "POSSIBLE_CODE_COLS = [\"product_no\",\"product_code\",\"code\",\"sku\",\"item_code\",\"à¸£à¸«à¸±à¸ª\",\"à¸£à¸«à¸±à¸ªà¸ªà¸´à¸™à¸„à¹‰à¸²\"]\n",
    "POSSIBLE_SIZE_COLS = [\"size\",\"unit\",\"size_text\",\"pack\",\"pack_size\",\"quantity\",\"volume\",\"weight\"]\n",
    "POSSIBLE_PRICE_COLS= [\"price\",\"final_price\",\"discounted_price\",\"sale_price\",\"current_price\",\"net_price\",\"à¸£à¸²à¸„à¸²\"]\n",
    "POSSIBLE_WAS_COLS  = [\"normal_price\",\"original_price\",\"was_price\",\"list_price\",\"à¸£à¸²à¸„à¸²à¹€à¸”à¸´à¸¡\"]\n",
    "\n",
    "def collect_alltext_by_source(rows_for_img: Dict[str, dict]) -> Dict[str, str]:\n",
    "    by_src: Dict[str, str] = {}\n",
    "    all_cols = set(POSSIBLE_TEXT_COLS + POSSIBLE_CODE_COLS + POSSIBLE_SIZE_COLS + POSSIBLE_PRICE_COLS + POSSIBLE_WAS_COLS)\n",
    "    for lab, row in rows_for_img.items():\n",
    "        parts = []\n",
    "        for cols in [POSSIBLE_TEXT_COLS, POSSIBLE_CODE_COLS, POSSIBLE_SIZE_COLS, POSSIBLE_PRICE_COLS, POSSIBLE_WAS_COLS]:\n",
    "            for c in cols:\n",
    "                if c in row and pd.notna(row[c]) and str(row[c]).strip():\n",
    "                    parts.append(str(row[c]).strip())\n",
    "        for c, v in row.items():\n",
    "            if c in all_cols: continue\n",
    "            if pd.notna(v) and isinstance(v, (str, int, float)):\n",
    "                sv = str(v).strip()\n",
    "                if sv: parts.append(sv)\n",
    "        by_src[lab] = \" \".join(parts).strip()\n",
    "    return by_src\n",
    "\n",
    "# ---------- Alignment ----------\n",
    "def multi_align_positions(tokens_by_src: Dict[str, List[str]]) -> List[List[Tuple[str, str]]]:\n",
    "    if not tokens_by_src:\n",
    "        return []\n",
    "    pivot_label = max(tokens_by_src.keys(), key=lambda k: len(tokens_by_src[k]))\n",
    "    pivot = tokens_by_src[pivot_label]\n",
    "    positions: List[List[Tuple[str, str]]] = [[(pivot_label, w)] for w in pivot]\n",
    "    if not positions:\n",
    "        for lab, toks in tokens_by_src.items():\n",
    "            if toks:\n",
    "                positions = [[(lab, w)] for w in toks]\n",
    "                pivot_label = lab\n",
    "                pivot = toks\n",
    "                break\n",
    "    for lab, toks in tokens_by_src.items():\n",
    "        if lab == pivot_label: continue\n",
    "        sm = difflib.SequenceMatcher(a=pivot, b=toks, autojunk=False)\n",
    "        pos_cursor = 0\n",
    "        for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "            if tag == \"equal\":\n",
    "                for k in range(i2 - i1):\n",
    "                    positions[i1 + k].append((lab, toks[j1 + k]))\n",
    "                pos_cursor = i2\n",
    "            elif tag == \"replace\":\n",
    "                pair = min(i2 - i1, j2 - j1)\n",
    "                for k in range(pair):\n",
    "                    if i1 + k < len(positions):\n",
    "                        positions[i1 + k].append((lab, toks[j1 + k]))\n",
    "                extra_b = (j2 - j1) - pair\n",
    "                for k in range(extra_b):\n",
    "                    insert_at = min(i2 + k, len(positions))\n",
    "                    positions.insert(insert_at, [(lab, toks[j1 + pair + k])])\n",
    "                pos_cursor = min(i2 + max(0, extra_b), len(positions))\n",
    "            elif tag == \"insert\":\n",
    "                for k in range(j1, j2):\n",
    "                    insert_at = min(pos_cursor, len(positions))\n",
    "                    positions.insert(insert_at, [(lab, toks[k])])\n",
    "                    pos_cursor = min(pos_cursor + 1, len(positions))\n",
    "            elif tag == \"delete\":\n",
    "                pos_cursor = i2\n",
    "    return positions\n",
    "\n",
    "def is_trivial(tok: str) -> bool:\n",
    "    if not tok: return False\n",
    "    s = tok.strip()\n",
    "    if re.fullmatch(r\"[\\d.,:/\\-+()%à¸¿xX]+\", s): return True\n",
    "    if any(u in s for u in THAI_UNIT_TOKENS): return True\n",
    "    return False\n",
    "\n",
    "def trim_candidates(cands: List[Tuple[str,str]]) -> List[Tuple[str,str]]:\n",
    "    seen = set(); out = []\n",
    "    for lab, w in cands:\n",
    "        w = (w or \"\").strip()\n",
    "        if not w: continue\n",
    "        key = (lab, w)\n",
    "        if key in seen: continue\n",
    "        seen.add(key)\n",
    "        out.append((lab, w))\n",
    "        if len(out) >= MAX_CANDIDATES_PER_POS: break\n",
    "    values = {w for _, w in out}\n",
    "    if len(values) == 1 and out:\n",
    "        return [out[0]]\n",
    "    return out\n",
    "\n",
    "# ===================== Product Name helpers =====================\n",
    "NAME_COLS_PRIMARY   = [\"product_name\", \"name\", \"title\"]\n",
    "PRICE_KEYWORDS_TH   = [\"à¸›à¸à¸•à¸´\", \"à¸à¸´à¹€à¸¨à¸©\", \"à¸£à¸²à¸„à¸²\", \"à¸šà¸²à¸—\", \"à¸¥à¸”\", \"à¹‚à¸›à¸£\", \"à¹à¸–à¸¡\", \"à¸‹à¸·à¹‰à¸­\", \"à¸Šà¸´à¹‰à¸™\", \"à¹à¸à¹‡à¸„\", \"à¹à¸à¸„\"]\n",
    "UNIT_PAT = r\"(à¸¡à¸¥\\.|à¸¥à¸´à¸•à¸£|à¸à¸£à¸±à¸¡|à¸\\.|à¸à¸\\.|à¸‚à¸§à¸”|à¸‹à¸­à¸‡|à¸à¸¥à¹ˆà¸­à¸‡|à¹à¸à¹‡à¸„|à¹à¸à¸„|à¸Šà¸´à¹‰à¸™|à¹à¸œà¸‡|à¸Šà¸¸à¸”|à¹à¸šà¸š|à¹„à¸‹à¸ªà¹Œ|à¹„à¸‹à¸‹à¹Œ)\"\n",
    "PRICE_PAT = r\"(à¸¿\\s*\\d[\\d.,]*|\\d[\\d.,]*\\s*(à¸šà¸²à¸—|à¸¿)|\\d+%|\\d+\\s*-\\.)\"\n",
    "\n",
    "def _penalize_noise(s: str) -> int:\n",
    "    p = 0\n",
    "    if re.search(r\"\\d\", str(s)): p += 2\n",
    "    if any(k in str(s) for k in PRICE_KEYWORDS_TH): p += 2\n",
    "    if re.search(UNIT_PAT, str(s)): p += 1\n",
    "    if len(str(s).split()) <= 1: p += 1\n",
    "    return p\n",
    "\n",
    "def _name_score(s: str) -> float:\n",
    "    core = re.sub(r\"[^A-Za-zà¸-à¹™\\s\\-&()/\\.]\", \"\", str(s)).strip()\n",
    "    return max(0, len(core)) - _penalize_noise(str(s))\n",
    "\n",
    "def _clean_from_fulltext(text: str) -> str:\n",
    "    if not text: return \"\"\n",
    "    t = str(text)\n",
    "    for kw in PRICE_KEYWORDS_TH:\n",
    "        if kw in t:\n",
    "            t = t.split(kw)[0]\n",
    "    t = re.sub(UNIT_PAT, \"\", t)\n",
    "    t = re.sub(PRICE_PAT, \"\", t)\n",
    "    t = re.sub(r\"\\b\\d[\\d.,]*\\b\", \"\", t)\n",
    "    t = re.sub(r\"[^A-Za-zà¸-à¹™\\s\\-&()/\\.]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    toks = t.split()\n",
    "    if len(toks) > 10:\n",
    "        t = \" \".join(toks[:10])\n",
    "    return t\n",
    "\n",
    "def pick_product_name(rows_for_img: dict, text_full: str) -> str:\n",
    "    cands = []\n",
    "    for row in rows_for_img.values():\n",
    "        for c in NAME_COLS_PRIMARY + POSSIBLE_TEXT_COLS:\n",
    "            v = row.get(c) or row.get(str(c).lower())\n",
    "            if v and isinstance(v, (str, int, float)):\n",
    "                sv = str(v).strip()\n",
    "                if sv:\n",
    "                    cands.append(sv)\n",
    "    scored = sorted(cands, key=lambda s: _name_score(str(s)), reverse=True)\n",
    "    if scored and _name_score(scored[0]) >= 3:\n",
    "        return to_one_line(scored[0])\n",
    "    h = _clean_from_fulltext(text_full)\n",
    "    return to_one_line(h)\n",
    "\n",
    "# ===================== Prompts =====================\n",
    "def prompt_field_bootstrap(run_id: str, image_path: str) -> str:\n",
    "    return f\"\"\"RUN_ID={run_id}\n",
    "THAI FIELD OCR BOOTSTRAP â€” à¸­à¹ˆà¸²à¸™ 'à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸—à¸µà¹ˆà¹€à¸«à¹‡à¸™à¹ƒà¸™à¸ à¸²à¸' à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡ CSV:\n",
    "- image={image_path}\n",
    "à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”:\n",
    "1) à¸­à¹ˆà¸²à¸™à¹€à¸‰à¸à¸²à¸°à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¸ˆà¸£à¸´à¸‡ (à¸•à¸²à¸¡à¸¥à¸³à¸”à¸±à¸šà¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¸•à¸²à¸¡à¸ à¸²à¸)\n",
    "2) à¸«à¹‰à¸²à¸¡à¹€à¸”à¸²/à¹à¸•à¹ˆà¸‡à¹€à¸•à¸´à¸¡ à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸«à¹‡à¸™à¹ƒà¸«à¹‰à¹€à¸§à¹‰à¸™à¸§à¹ˆà¸²à¸‡\n",
    "3) à¸•à¸­à¸š JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™:\n",
    "{{\n",
    "  \"text\": \"<à¸ªà¸•à¸£à¸´à¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¹ƒà¸™à¸ à¸²à¸>\"\n",
    "}}\"\"\"\n",
    "\n",
    "def prompt_token_pick_batch(run_id: str, image_path: str,\n",
    "                            batch_positions: List[dict],\n",
    "                            context_texts: Dict[str, str]) -> str:\n",
    "    ctx_lines  = [f\"- {lab}_full: {to_one_line(context_texts.get(lab,''))}\" for lab in sorted(context_texts.keys())]\n",
    "    trimmed_items = []\n",
    "    for it in batch_positions:\n",
    "        c = it.get(\"candidates\", [])\n",
    "        trimmed_items.append({\"idx\": it.get(\"idx\", -1),\n",
    "                              \"candidates\": [[lab, w] for lab, w in c]})\n",
    "    return (\n",
    "f\"\"\"RUN_ID={run_id}\n",
    "THAI TOKEN PICK (BATCH) â€” à¹€à¸¥à¸·à¸­à¸à¹‚à¸—à¹€à¸„à¹‡à¸™à¸•à¹ˆà¸­à¹‚à¸—à¹€à¸„à¹‡à¸™à¸ˆà¸²à¸ CSV à¸”à¹‰à¸§à¸¢à¸ à¸²à¸à¸ˆà¸£à¸´à¸‡:\n",
    "- image={image_path}\n",
    "\n",
    "à¸à¸•à¸´à¸à¸²à¸•à¹ˆà¸­ item:\n",
    "1) à¸–à¹‰à¸²à¹‚à¸—à¹€à¸„à¹‡à¸™à¸ˆà¸²à¸ candidates à¸•à¸£à¸‡à¸à¸±à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸šà¸™à¸ à¸²à¸ â†’ à¹€à¸¥à¸·à¸­à¸ (picked_label, picked_token)\n",
    "2) à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¹‚à¸—à¹€à¸„à¹‡à¸™à¹ƒà¸”à¹ƒà¸™ candidates à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¸ à¸²à¸ â†’ à¸•à¸±à¹‰à¸‡ ocr_fallback=true à¹à¸¥à¸°à¸–à¸­à¸”à¸ˆà¸²à¸à¸ à¸²à¸à¹€à¸›à¹‡à¸™ new_token\n",
    "3) à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡à¸„à¸³à¹ƒà¸«à¸¡à¹ˆ/à¸œà¸ªà¸¡à¸„à¸³à¸ˆà¸²à¸à¸«à¸¥à¸²à¸¢à¹à¸«à¸¥à¹ˆà¸‡à¹€à¸­à¸‡\n",
    "\n",
    "context (à¸ªà¸³à¸«à¸£à¸±à¸šà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¸ à¸²à¸à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™):\n",
    "\"\"\" + \"\\n\".join(ctx_lines) + \"\"\"\n",
    "\n",
    "à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON array à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™:\n",
    "[\n",
    "  {\n",
    "    \"idx\": <int>,\n",
    "    \"picked_label\": \"<label à¸«à¸£à¸·à¸­ \\\"\\\">\",\n",
    "    \"picked_token\": \"<à¹‚à¸—à¹€à¸„à¹‡à¸™à¸ˆà¸²à¸ CSV à¸«à¸£à¸·à¸­ \\\"\\\">\",\n",
    "    \"confidence\": <0.0-1.0>,\n",
    "    \"ocr_fallback\": <true|false>,\n",
    "    \"new_token\": \"<à¸–à¹‰à¸² OCR-fallback; à¸¡à¸´à¸‰à¸°à¸™à¸±à¹‰à¸™ \\\"\\\">\"\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "\n",
    "items:\n",
    "\"\"\" + json.dumps(trimmed_items, ensure_ascii=False)\n",
    ")\n",
    "\n",
    "# ===================== LLM calls =====================\n",
    "def _safe_load_json(text: str):\n",
    "    if not text:\n",
    "        return None\n",
    "    s = CONTROL_RE.sub(\"\", text).strip()\n",
    "    if \"```\" in s:\n",
    "        parts = [p for p in s.split(\"```\") if p.strip()]\n",
    "        s = max(parts, key=len)\n",
    "    s = s.strip()\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        try:\n",
    "            beg_obj, beg_arr = s.find(\"{\"), s.find(\"[\")\n",
    "            if beg_obj == -1 and beg_arr == -1:\n",
    "                return None\n",
    "            beg = len(s) if beg_obj == -1 else beg_obj\n",
    "            if beg_arr != -1: beg = min(beg, beg_arr)\n",
    "            tail = s.rfind(\"}\") if beg == beg_obj else s.rfind(\"]\")\n",
    "            if tail != -1 and tail > beg:\n",
    "                return json.loads(s[beg:tail+1])\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def call_field_bootstrap(img_path: str, image_part: Any) -> str:\n",
    "    client = build_client()\n",
    "    parts = [prompt_field_bootstrap(RUN_ID, img_path), image_part]\n",
    "    cfg = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET),\n",
    "        max_output_tokens=MAX_OUTPUT_TOKENS,\n",
    "        response_mime_type=\"application/json\",\n",
    "        temperature=TEMPERATURE, top_p=TOP_P, top_k=TOP_K,\n",
    "    )\n",
    "    delay = THROTTLE_SEC\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            if attempt == 0 and delay > 0: time.sleep(delay)\n",
    "            resp = client.models.generate_content(model=MODEL, contents=parts, config=cfg)\n",
    "            text = (getattr(resp, \"text\", None) or \"\").strip()\n",
    "            obj = _safe_load_json(text)\n",
    "            if isinstance(obj, dict):\n",
    "                return to_one_line(str(obj.get(\"text\",\"\") or \"\"))\n",
    "            return \"\"\n",
    "        except Exception as e:\n",
    "            m = str(e).lower()\n",
    "            transient = any(k in m for k in [\n",
    "                \"remoteprotocolerror\",\"server disconnected\",\"disconnect\",\"connection reset\",\"connection aborted\",\n",
    "                \"broken pipe\",\"eof\",\"timeout\",\"temporarily unavailable\",\"protocol error\",\n",
    "                \"503\",\"unavailable\",\"internal\",\"deadline\",\"upstream\"\n",
    "            ])\n",
    "            rate = any(k in m for k in [\"429\",\"quota\",\"too many requests\",\"exceeded\",\"resourceexhausted\",\"rate\"])\n",
    "            if transient:\n",
    "                delay = min(max(3.0, (delay or 1.5)*1.6), 120.0)\n",
    "                time.sleep(delay + random.uniform(0,0.7)); rotator.rotate(); continue\n",
    "            if rate:\n",
    "                if not rotator.rotate():\n",
    "                    delay = min(max(4.0, (delay or 1.5)*1.8), 120.0)\n",
    "                else:\n",
    "                    delay = 0.8\n",
    "                time.sleep(delay + random.uniform(0,0.5)); continue\n",
    "            log(f\"âŒ field_bootstrap error: {e}\")\n",
    "            return \"\"\n",
    "    return \"\"\n",
    "\n",
    "def call_token_picker_batch(img_path: str,\n",
    "                            items: List[dict],\n",
    "                            context_texts: Dict[str, str],\n",
    "                            image_part: Any) -> List[dict]:\n",
    "    if not items: return []\n",
    "    client = build_client()\n",
    "    prompt = prompt_token_pick_batch(RUN_ID, img_path, items, context_texts)\n",
    "    parts = [prompt, image_part]\n",
    "    cfg = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=THINKING_BUDGET),\n",
    "        max_output_tokens=max(256, min(2048, 80 * len(items))),\n",
    "        response_mime_type=\"application/json\",\n",
    "        temperature=TEMPERATURE, top_p=TOP_P, top_k=TOP_K,\n",
    "    )\n",
    "    delay = THROTTLE_SEC\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            if attempt == 0 and delay > 0: time.sleep(delay)\n",
    "            resp = client.models.generate_content(model=MODEL, contents=parts, config=cfg)\n",
    "            text = (getattr(resp, \"text\", None) or \"\").strip()\n",
    "            arr = _safe_load_json(text)\n",
    "            out = []\n",
    "            if isinstance(arr, dict):\n",
    "                arr = arr.get(\"results\", [])\n",
    "            if isinstance(arr, list):\n",
    "                for obj in arr:\n",
    "                    try:\n",
    "                        out.append({\n",
    "                            \"idx\"          : int(obj.get(\"idx\", -1)),\n",
    "                            \"picked_label\" : to_one_line(str(obj.get(\"picked_label\",\"\") or \"\")),\n",
    "                            \"picked_token\" : to_one_line(str(obj.get(\"picked_token\",\"\") or \"\")),\n",
    "                            \"confidence\"   : float(obj.get(\"confidence\",0.0) or 0.0),\n",
    "                            \"ocr_fallback\" : bool(obj.get(\"ocr_fallback\", False)),\n",
    "                            \"new_token\"    : to_one_line(str(obj.get(\"new_token\",\"\") or \"\")),\n",
    "                        })\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return out\n",
    "        except Exception as e:\n",
    "            m = str(e).lower()\n",
    "            transient = any(k in m for k in [\n",
    "                \"remoteprotocolerror\",\"server disconnected\",\"disconnect\",\"connection reset\",\"connection aborted\",\n",
    "                \"broken pipe\",\"eof\",\"timeout\",\"temporarily unavailable\",\"protocol error\",\n",
    "                \"503\",\"unavailable\",\"internal\",\"deadline\",\"upstream\"\n",
    "            ])\n",
    "            rate = any(k in m for k in [\"429\",\"quota\",\"too many requests\",\"exceeded\",\"resourceexhausted\",\"rate\"])\n",
    "            if transient:\n",
    "                delay = min(max(3.0, (delay or 1.5)*1.6), 120.0)\n",
    "                time.sleep(delay + random.uniform(0,0.7)); rotator.rotate(); continue\n",
    "            if rate:\n",
    "                if not rotator.rotate():\n",
    "                    delay = min(max(4.0, (delay or 1.5)*1.8), 120.0)\n",
    "                else:\n",
    "                    delay = 0.8\n",
    "                time.sleep(delay + random.uniform(0,0.5)); continue\n",
    "            log(f\"âŒ token_picker_batch error: {e}\")\n",
    "            return [{\"idx\": it.get(\"idx\",-1), \"picked_label\":\"\", \"picked_token\":\"\", \"confidence\":0.0, \"ocr_fallback\":False, \"new_token\":\"\", \"notes\": f\"err:{e!r}\"} for it in items]\n",
    "    return [{\"idx\": it.get(\"idx\",-1), \"picked_label\":\"\", \"picked_token\":\"\", \"confidence\":0.0, \"ocr_fallback\":False, \"new_token\":\"\", \"notes\":\"retry_exhausted\"} for it in items]\n",
    "\n",
    "# ===================== Main =====================\n",
    "def main():\n",
    "    global IMAGE_INDEX\n",
    "    if not IMAGE_ROOT.exists():\n",
    "        log(f\"âš ï¸ IMAGE_ROOT not found: {IMAGE_ROOT}\")\n",
    "    IMAGE_INDEX = index_images(IMAGE_ROOT)\n",
    "\n",
    "    ensure_dir(OUT_JSONL); ensure_dir(OUT_CSV)\n",
    "    clear_outputs()\n",
    "    open(OUT_JSONL, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    # à¹‚à¸«à¸¥à¸” CSV â†’ dict image_key -> row\n",
    "    rows_by_label: Dict[str, Dict[str, dict]] = {}\n",
    "    for lab, pth in CSV_FILES:\n",
    "        rows_by_label[lab] = load_rows(Path(pth))\n",
    "        log(f\"ğŸ“„ {lab} CSV keys (raw): {len(rows_by_label[lab])}\")\n",
    "\n",
    "    # mapping: resolved image path -> set(keys à¸—à¸µà¹ˆà¸­à¹‰à¸²à¸‡à¸–à¸¶à¸‡à¸£à¸¹à¸›à¸™à¸±à¹‰à¸™)\n",
    "    resolved_to_keys: Dict[str, set] = {}\n",
    "    for _, mp in rows_by_label.items():\n",
    "        for k in mp.keys():\n",
    "            rp = resolve_image_path(k) or resolve_image_path(Path(k).name)\n",
    "            if rp is None: continue\n",
    "            rps = str(rp)\n",
    "            resolved_to_keys.setdefault(rps, set()).add(k)\n",
    "            resolved_to_keys[rps].add(Path(k).name)\n",
    "\n",
    "    all_resolved = sorted(resolved_to_keys.keys())\n",
    "    log(f\"ğŸ§® Images (unique, resolved): {len(all_resolved)}\")\n",
    "\n",
    "    out_rows = []  # à¸ªà¸³à¸«à¸£à¸±à¸š CSV\n",
    "\n",
    "    for resolved_str in tqdm(all_resolved, desc=\"Token-by-Token pick (batch)\"):\n",
    "        img_path = Path(resolved_str)\n",
    "        if not img_path.exists():\n",
    "            log(f\"[skip] image not found: {resolved_str}\")\n",
    "            continue\n",
    "\n",
    "        # à¸£à¸§à¸¡à¹à¸–à¸§à¸•à¸²à¸¡ key à¸—à¸µà¹ˆ match à¸£à¸¹à¸›à¸™à¸µà¹‰\n",
    "        possible_keys = resolved_to_keys[resolved_str]\n",
    "        rows_for_img: Dict[str, dict] = {}\n",
    "        for lab, mp in rows_by_label.items():\n",
    "            found = None\n",
    "            for k in possible_keys:\n",
    "                if k in mp: found = mp[k]; break\n",
    "            if not found:\n",
    "                for k in possible_keys:\n",
    "                    base = Path(k).name\n",
    "                    if base in mp: found = mp[base]; break\n",
    "            if not found and resolved_str in mp:\n",
    "                found = mp[resolved_str]\n",
    "            if found:\n",
    "                rows_for_img[lab] = found\n",
    "\n",
    "        if not rows_for_img:\n",
    "            log(f\"[skip] no rows for resolved image: {resolved_str}\")\n",
    "            continue\n",
    "\n",
    "        # à¸£à¸§à¸¡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸¸à¸à¹à¸«à¸¥à¹ˆà¸‡\n",
    "        alltext_by_src = {lab: to_one_line(txt) for lab, txt in collect_alltext_by_source(rows_for_img).items()}\n",
    "        tokens_by_src: Dict[str, List[str]] = {lab: tokenize_all_text(txt) for lab, txt in alltext_by_src.items()}\n",
    "\n",
    "        image_part = get_image_part_for(img_path)\n",
    "\n",
    "        # à¸–à¹‰à¸² CSV à¸§à¹ˆà¸²à¸‡à¸—à¸¸à¸à¹à¸«à¸¥à¹ˆà¸‡ â†’ OCR à¸—à¸±à¹‰à¸‡à¸ à¸²à¸ (bootstrap)\n",
    "        if not any(tokens_by_src.values()):\n",
    "            boot_txt = call_field_bootstrap(str(img_path), image_part)\n",
    "            final_text = to_one_line(clean_for_all_text(boot_txt)) if boot_txt else \"\"\n",
    "            product_name = to_one_line(pick_product_name(rows_for_img, final_text))\n",
    "            with open(OUT_JSONL, \"a\", encoding=\"utf-8\") as fout:\n",
    "                fout.write(json.dumps({\n",
    "                    \"run_id\":RUN_ID,\"image\":resolved_str,\"image_key\":Path(resolved_str).name,\n",
    "                    \"text_full\":final_text,\"text_llm_only\":final_text,\"product_name\":product_name,\n",
    "                    \"decisions\":[{\"mode\":\"bootstrap\"}]}, ensure_ascii=False) + \"\\n\")\n",
    "            out_rows.append({\"image\":resolved_str, \"product_name\": product_name,\n",
    "                             \"text_full\": final_text, \"text_llm_only\": final_text})\n",
    "            continue\n",
    "\n",
    "        # à¸ˆà¸±à¸”à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡\n",
    "        positions = multi_align_positions(tokens_by_src)\n",
    "        total_pos = len(positions)\n",
    "        if total_pos == 0:\n",
    "            boot_txt = call_field_bootstrap(str(img_path), image_part)\n",
    "            final_text = to_one_line(clean_for_all_text(boot_txt)) if boot_txt else \"\"\n",
    "            product_name = to_one_line(pick_product_name(rows_for_img, final_text))\n",
    "            with open(OUT_JSONL, \"a\", encoding=\"utf-8\") as fout:\n",
    "                fout.write(json.dumps({\n",
    "                    \"run_id\":RUN_ID,\"image\":resolved_str,\"image_key\":Path(resolved_str).name,\n",
    "                    \"text_full\":final_text,\"text_llm_only\":final_text,\"product_name\":product_name,\n",
    "                    \"decisions\":[{\"mode\":\"bootstrap_empty_positions\"}]}, ensure_ascii=False) + \"\\n\")\n",
    "            out_rows.append({\"image\":resolved_str, \"product_name\":product_name,\n",
    "                             \"text_full\": final_text, \"text_llm_only\": final_text})\n",
    "            continue\n",
    "\n",
    "        final_tokens = [\"\"] * total_pos\n",
    "        llm_only_tokens = [\"\"] * total_pos\n",
    "        decisions: List[dict] = []\n",
    "\n",
    "        need_llm_items = []\n",
    "        for pos_idx, cands in enumerate(positions):\n",
    "            cands = trim_candidates(cands)\n",
    "            cand_vals = [w for _, w in cands if w]\n",
    "\n",
    "            if not cand_vals:\n",
    "                need_llm_items.append({\"idx\": pos_idx, \"candidates\": []})\n",
    "                continue\n",
    "\n",
    "            if len(set(cand_vals)) == 1:\n",
    "                tok = cand_vals[0]\n",
    "                final_tokens[pos_idx] = tok\n",
    "                decisions.append({\"pos\":pos_idx,\"total\":total_pos,\"mode\":\"auto_equal\",\"token\":tok,\"candidates\":cands})\n",
    "                continue\n",
    "\n",
    "            if any(is_trivial(w) for w in cand_vals) and len(set(cand_vals)) <= 2:\n",
    "                tok = max(cand_vals, key=len)\n",
    "                final_tokens[pos_idx] = tok\n",
    "                decisions.append({\"pos\":pos_idx,\"total\":total_pos,\"mode\":\"auto_trivial\",\"token\":tok,\"candidates\":cands})\n",
    "                continue\n",
    "\n",
    "            need_llm_items.append({\"idx\": pos_idx, \"candidates\": cands})\n",
    "\n",
    "        force_round = []\n",
    "        if need_llm_items:\n",
    "            for i in range(0, len(need_llm_items), BATCH_POS if USE_BATCH else 1):\n",
    "                chunk = need_llm_items[i:i+(BATCH_POS if USE_BATCH else 1)]\n",
    "                items_for_prompt = [{\"idx\":it[\"idx\"], \"candidates\":it[\"candidates\"]} for it in chunk]\n",
    "                res_list = call_token_picker_batch(str(img_path), items_for_prompt, alltext_by_src, image_part)\n",
    "                res_by_idx = {r.get(\"idx\"): r for r in res_list} if res_list else {}\n",
    "\n",
    "                for it in chunk:\n",
    "                    pos_idx = it[\"idx\"]\n",
    "                    cands   = it[\"candidates\"]\n",
    "                    res = res_by_idx.get(pos_idx, {}) if res_by_idx else {}\n",
    "                    picked = to_one_line(res.get(\"picked_token\") or \"\")\n",
    "                    llm_conf = float(res.get(\"confidence\", 0.0) or 0.0)\n",
    "                    ocr_fb = bool(res.get(\"ocr_fallback\", False))\n",
    "                    new_tok = to_one_line(res.get(\"new_token\") or \"\")\n",
    "\n",
    "                    if ocr_fb:\n",
    "                        tok = new_tok\n",
    "                        final_tokens[pos_idx] = tok\n",
    "                        llm_only_tokens[pos_idx] = tok\n",
    "                        decisions.append({\n",
    "                            \"pos\":pos_idx,\"total\":total_pos,\"mode\":\"ocr_fallback\",\n",
    "                            \"picked_label\": \"\", \"picked_token\": \"\", \"new_token\": tok,\n",
    "                            \"llm_conf\": llm_conf, \"candidates\": cands\n",
    "                        })\n",
    "                    else:\n",
    "                        if picked and any(picked == v for _, v in cands):\n",
    "                            tok = picked\n",
    "                            final_tokens[pos_idx] = tok\n",
    "                            llm_only_tokens[pos_idx] = tok\n",
    "                            decisions.append({\n",
    "                                \"pos\":pos_idx,\"total\":total_pos,\"mode\":\"llm_pick\",\n",
    "                                \"picked_label\": to_one_line(res.get(\"picked_label\",\"\")),\n",
    "                                \"picked_token\": tok, \"new_token\":\"\", \"llm_conf\": llm_conf, \"candidates\": cands\n",
    "                            })\n",
    "                        else:\n",
    "                            force_round.append({\"idx\": pos_idx, \"candidates\": []})\n",
    "                            decisions.append({\n",
    "                                \"pos\":pos_idx,\"total\":total_pos,\"mode\":\"force_ocr_pending\",\n",
    "                                \"picked_label\": to_one_line(res.get(\"picked_label\",\"\")),\n",
    "                                \"picked_token\": picked, \"new_token\":\"\", \"llm_conf\": llm_conf, \"candidates\": cands\n",
    "                            })\n",
    "            if force_round:\n",
    "                for i in range(0, len(force_round), BATCH_POS if USE_BATCH else 1):\n",
    "                    chunk = force_round[i:i+(BATCH_POS if USE_BATCH else 1)]\n",
    "                    res_list = call_token_picker_batch(str(img_path), chunk, alltext_by_src, image_part)\n",
    "                    res_by_idx = {r.get(\"idx\"): r for r in res_list} if res_list else {}\n",
    "                    for it in chunk:\n",
    "                        pos_idx = it[\"idx\"]\n",
    "                        res = res_by_idx.get(pos_idx, {}) if res_by_idx else {}\n",
    "                        new_tok = to_one_line(res.get(\"new_token\") or \"\")\n",
    "                        if new_tok:\n",
    "                            final_tokens[pos_idx] = new_tok\n",
    "                            llm_only_tokens[pos_idx] = new_tok\n",
    "                            decisions.append({\n",
    "                                \"pos\": pos_idx, \"total\": total_pos, \"mode\": \"force_ocr_done\",\n",
    "                                \"picked_label\":\"\", \"picked_token\":\"\", \"new_token\": new_tok,\n",
    "                                \"llm_conf\": float(res.get(\"confidence\",0.0) or 0.0), \"candidates\": []\n",
    "                            })\n",
    "                        else:\n",
    "                            final_tokens[pos_idx] = \"\"\n",
    "                            decisions.append({\n",
    "                                \"pos\": pos_idx, \"total\": total_pos, \"mode\": \"force_ocr_failed\",\n",
    "                                \"picked_label\":\"\", \"picked_token\":\"\", \"new_token\":\"\", \"llm_conf\": 0.0, \"candidates\": []\n",
    "                            })\n",
    "\n",
    "        # ------- à¸ªà¸£à¸¸à¸› text + product_name (à¸šà¸£à¸£à¸—à¸±à¸”à¹€à¸”à¸µà¸¢à¸§) -------\n",
    "        text_full = to_one_line(join_tokens_all(final_tokens))\n",
    "        text_llm_only = to_one_line(join_tokens_all([t for t in llm_only_tokens if t]))\n",
    "        product_name = to_one_line(pick_product_name(rows_for_img, text_full))\n",
    "\n",
    "        out_json = {\n",
    "            \"run_id\": RUN_ID,\n",
    "            \"image\": resolved_str,\n",
    "            \"image_key\": Path(resolved_str).name,\n",
    "            \"text_full\": text_full,\n",
    "            \"text_llm_only\": text_llm_only,\n",
    "            \"product_name\": product_name,\n",
    "            \"decisions\": decisions\n",
    "        }\n",
    "        with open(OUT_JSONL, \"a\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(json.dumps(out_json, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        out_rows.append({\n",
    "            \"image\": resolved_str,\n",
    "            \"product_name\": product_name,\n",
    "            \"text_full\": text_full,\n",
    "            \"text_llm_only\": text_llm_only\n",
    "        })\n",
    "\n",
    "    # ------- Save CSV -------\n",
    "    ensure_dir(OUT_CSV)\n",
    "    df = pd.DataFrame(out_rows)\n",
    "    if ONLY_PRODUCT_NAME:\n",
    "        df = df[[\"image\", \"product_name\"]]\n",
    "    else:\n",
    "        df = df[[\"image\",\"product_name\",\"text_full\",\"text_llm_only\"]]\n",
    "    df = df.applymap(to_one_line)\n",
    "    df.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\", lineterminator=\"\\n\")\n",
    "\n",
    "    print(\"âœ… Done.\")\n",
    "    print(\"JSONL:\", OUT_JSONL)\n",
    "    print(\"CSV  :\", OUT_CSV)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09f6f4",
   "metadata": {},
   "source": [
    "## 3. OCR.space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135905dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Resuming. Already have 271 rows in ocr_results_2025-07-03.csv\n",
      "[1/275] 2025-11-04_detail_0001.jpg  â­ï¸  (skip: already OK)\n",
      "[2/275] 2025-11-04_detail_0002.jpg  â­ï¸  (skip: already OK)\n",
      "[3/275] 2025-11-04_detail_0003.jpg  â­ï¸  (skip: already OK)\n",
      "[4/275] 2025-11-04_detail_0004.jpg  â­ï¸  (skip: already OK)\n",
      "[5/275] 2025-11-04_detail_0005.jpg  â­ï¸  (skip: already OK)\n",
      "[6/275] 2025-11-04_detail_0006.jpg  â­ï¸  (skip: already OK)\n",
      "[7/275] 2025-11-04_detail_0007.jpg  â­ï¸  (skip: already OK)\n",
      "[8/275] 2025-11-04_detail_0008.jpg  â­ï¸  (skip: already OK)\n",
      "[9/275] 2025-11-04_detail_0009.jpg  â­ï¸  (skip: already OK)\n",
      "[10/275] 2025-11-04_detail_0010.jpg  â­ï¸  (skip: already OK)\n",
      "[11/275] 2025-11-04_detail_0011.jpg  â­ï¸  (skip: already OK)\n",
      "[12/275] 2025-11-04_detail_0012.jpg  â­ï¸  (skip: already OK)\n",
      "[13/275] 2025-11-04_detail_0013.jpg  â­ï¸  (skip: already OK)\n",
      "[14/275] 2025-11-04_detail_0014.jpg  â­ï¸  (skip: already OK)\n",
      "[15/275] 2025-11-04_detail_0015.jpg  â­ï¸  (skip: already OK)\n",
      "[16/275] 2025-11-04_detail_0016.jpg  â­ï¸  (skip: already OK)\n",
      "[17/275] 2025-11-04_detail_0017.jpg  â­ï¸  (skip: already OK)\n",
      "[18/275] 2025-11-04_detail_0018.jpg  â­ï¸  (skip: already OK)\n",
      "[19/275] 2025-11-04_detail_0019.jpg  â­ï¸  (skip: already OK)\n",
      "[20/275] 2025-11-04_detail_0020.jpg  â­ï¸  (skip: already OK)\n",
      "[21/275] 2025-11-04_detail_0021.jpg  â­ï¸  (skip: already OK)\n",
      "[22/275] 2025-11-04_detail_0022.jpg  â­ï¸  (skip: already OK)\n",
      "[23/275] 2025-11-04_detail_0023.jpg  â­ï¸  (skip: already OK)\n",
      "[24/275] 2025-11-04_detail_0024.jpg  â­ï¸  (skip: already OK)\n",
      "[25/275] 2025-11-04_detail_0025.jpg  â­ï¸  (skip: already OK)\n",
      "[26/275] 2025-11-04_detail_0026.jpg  â­ï¸  (skip: already OK)\n",
      "[27/275] 2025-11-04_detail_0027.jpg  â­ï¸  (skip: already OK)\n",
      "[28/275] 2025-11-04_detail_0028.jpg  â­ï¸  (skip: already OK)\n",
      "[29/275] 2025-11-04_detail_0029.jpg  â­ï¸  (skip: already OK)\n",
      "[30/275] 2025-11-04_detail_0030.jpg  â­ï¸  (skip: already OK)\n",
      "[31/275] 2025-11-04_detail_0031.jpg  â­ï¸  (skip: already OK)\n",
      "[32/275] 2025-11-04_detail_0032.jpg  â­ï¸  (skip: already OK)\n",
      "[33/275] 2025-11-04_detail_0033.jpg  â­ï¸  (skip: already OK)\n",
      "[34/275] 2025-11-04_detail_0034.jpg  â­ï¸  (skip: already OK)\n",
      "[35/275] 2025-11-04_detail_0035.jpg  â­ï¸  (skip: already OK)\n",
      "[36/275] 2025-11-04_detail_0036.jpg  â­ï¸  (skip: already OK)\n",
      "[37/275] 2025-11-04_detail_0037.jpg  â­ï¸  (skip: already OK)\n",
      "[38/275] 2025-11-04_detail_0038.jpg  â­ï¸  (skip: already OK)\n",
      "[39/275] 2025-11-04_detail_0039.jpg  â­ï¸  (skip: already OK)\n",
      "[40/275] 2025-11-04_detail_0040.jpg  â­ï¸  (skip: already OK)\n",
      "[41/275] 2025-11-04_detail_0041.jpg  â­ï¸  (skip: already OK)\n",
      "[42/275] 2025-11-04_detail_0042.jpg  â­ï¸  (skip: already OK)\n",
      "[43/275] 2025-11-04_detail_0043.jpg  â­ï¸  (skip: already OK)\n",
      "[44/275] 2025-11-04_detail_0044.jpg  â­ï¸  (skip: already OK)\n",
      "[45/275] 2025-11-04_detail_0045.jpg  â­ï¸  (skip: already OK)\n",
      "[46/275] 2025-11-04_detail_0046.jpg  â­ï¸  (skip: already OK)\n",
      "[47/275] 2025-11-04_detail_0047.jpg  â­ï¸  (skip: already OK)\n",
      "[48/275] 2025-11-04_detail_0048.jpg  â­ï¸  (skip: already OK)\n",
      "[49/275] 2025-11-04_detail_0049.jpg  â­ï¸  (skip: already OK)\n",
      "[50/275] 2025-11-04_detail_0050.jpg  â­ï¸  (skip: already OK)\n",
      "[51/275] 2025-11-04_detail_0051.jpg  â­ï¸  (skip: already OK)\n",
      "[52/275] 2025-11-04_detail_0052.jpg  â­ï¸  (skip: already OK)\n",
      "[53/275] 2025-11-04_detail_0053.jpg  â­ï¸  (skip: already OK)\n",
      "[54/275] 2025-11-04_detail_0054.jpg  â­ï¸  (skip: already OK)\n",
      "[55/275] 2025-11-04_detail_0055.jpg  â­ï¸  (skip: already OK)\n",
      "[56/275] 2025-11-04_detail_0056.jpg  â­ï¸  (skip: already OK)\n",
      "[57/275] 2025-11-04_detail_0057.jpg  â­ï¸  (skip: already OK)\n",
      "[58/275] 2025-11-04_detail_0058.jpg  â­ï¸  (skip: already OK)\n",
      "[59/275] 2025-11-04_detail_0059.jpg  â­ï¸  (skip: already OK)\n",
      "[60/275] 2025-11-04_detail_0060.jpg  â­ï¸  (skip: already OK)\n",
      "[61/275] 2025-11-04_detail_0061.jpg  â­ï¸  (skip: already OK)\n",
      "[62/275] 2025-11-04_detail_0062.jpg  â­ï¸  (skip: already OK)\n",
      "[63/275] 2025-11-04_detail_0063.jpg  â­ï¸  (skip: already OK)\n",
      "[64/275] 2025-11-04_detail_0064.jpg  â­ï¸  (skip: already OK)\n",
      "[65/275] 2025-11-04_detail_0065.jpg  â­ï¸  (skip: already OK)\n",
      "[66/275] 2025-11-04_detail_0066.jpg  â­ï¸  (skip: already OK)\n",
      "[67/275] 2025-11-04_detail_0067.jpg  â­ï¸  (skip: already OK)\n",
      "[68/275] 2025-11-04_detail_0068.jpg  â­ï¸  (skip: already OK)\n",
      "[69/275] 2025-11-04_detail_0069.jpg  â­ï¸  (skip: already OK)\n",
      "[70/275] 2025-11-04_detail_0070.jpg  â­ï¸  (skip: already OK)\n",
      "[71/275] 2025-11-04_detail_0071.jpg  â­ï¸  (skip: already OK)\n",
      "[72/275] 2025-11-04_detail_0072.jpg  â­ï¸  (skip: already OK)\n",
      "[73/275] 2025-11-04_detail_0073.jpg  â­ï¸  (skip: already OK)\n",
      "[74/275] 2025-11-04_detail_0074.jpg  â­ï¸  (skip: already OK)\n",
      "[75/275] 2025-11-04_detail_0075.jpg  â­ï¸  (skip: already OK)\n",
      "[76/275] 2025-11-04_detail_0076.jpg  â­ï¸  (skip: already OK)\n",
      "[77/275] 2025-11-04_detail_0077.jpg  â­ï¸  (skip: already OK)\n",
      "[78/275] 2025-11-04_detail_0078.jpg  â­ï¸  (skip: already OK)\n",
      "[79/275] 2025-11-04_detail_0079.jpg  â­ï¸  (skip: already OK)\n",
      "[80/275] 2025-11-04_detail_0080.jpg  â­ï¸  (skip: already OK)\n",
      "[81/275] 2025-11-04_detail_0081.jpg  â­ï¸  (skip: already OK)\n",
      "[82/275] 2025-11-04_detail_0082.jpg\n",
      "   â†ªï¸ API body error -> retry 1/5 in 1.5s (E101_or_timeout: E101: Timed out waiting for results)\n",
      "   â†ªï¸ API body error -> retry 2/5 in 2.2s (E101_or_timeout: E101: Timed out waiting for results)\n",
      "   â†ªï¸ API body error -> retry 3/5 in 4.2s (E101_or_timeout: E101: Timed out waiting for results)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Robust OCR.Space runner for Thai (v2.2 anti-E101 + smart enlarge):\n",
    "- à¹ƒà¸Šà¹‰ OCREngine=2 + language 'tha' (à¸«à¸£à¸·à¸­ 'auto' à¸–à¹‰à¸²à¸ à¸²à¸©à¸²à¸›à¸™)\n",
    "- à¸ˆà¸±à¸š E101: Timed out waiting for results à¹à¸¥à¹‰à¸§ fallback (à¸¢à¹ˆà¸­à¸ à¸²à¸à¹€à¸à¸´à¹ˆà¸¡/à¸¥à¸”à¸„à¸¸à¸“à¸ à¸²à¸ + à¹€à¸à¸´à¹ˆà¸¡ timeout)\n",
    "- Retries + exponential backoff (+ jitter) à¸šà¸™ timeout/5xx/429/E101\n",
    "- à¸‚à¸¢à¸²à¸¢à¸ à¸²à¸à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸–à¹‰à¸²à¸ à¸²à¸à¹€à¸¥à¹‡à¸ (LANCZOS) à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ OCR à¸­à¹ˆà¸²à¸™à¸Šà¸±à¸”à¸‚à¸¶à¹‰à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸­à¸”à¸µ\n",
    "- à¹€à¸‚à¸µà¸¢à¸™ CSV à¹à¸šà¸š incremental à¹à¸¥à¸° resume à¹„à¸”à¹‰ (à¸‚à¹‰à¸²à¸¡à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸ªà¸³à¹€à¸£à¹‡à¸ˆà¹à¸¥à¹‰à¸§)\n",
    "\"\"\"\n",
    "\n",
    "import io, time, csv, sys, os, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "import requests\n",
    "from requests.exceptions import ReadTimeout, ConnectTimeout, ConnectionError as ReqConnErr\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# ================= CONFIG =================\n",
    "API_URL  = \"https://api.ocr.space/parse/image\"\n",
    "API_KEY  = \"Key ocr.space\".strip()  # <- key à¸‚à¸­à¸‡ ocr.space\n",
    "\n",
    "# à¸ à¸²à¸©à¸²/à¹€à¸­à¸™à¸ˆà¸´à¸™: à¹„à¸—à¸¢à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰ Engine 2 à¹€à¸ªà¸¡à¸­\n",
    "LANGUAGE = \"tha\"        # à¸«à¸£à¸·à¸­ \"auto\" à¸–à¹‰à¸²à¸£à¸¹à¸›à¸¡à¸µà¸«à¸¥à¸²à¸¢à¸ à¸²à¸©à¸²\n",
    "ENGINE   = 2            # à¹„à¸—à¸¢à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¹ƒà¸™ Engine 2 à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™\n",
    "\n",
    "IMAGE_DIR  = Path(r\"C:\\projecteve\\OCR\\data\\yolo_crop\\output_detail_only2025-11-04\")\n",
    "OUTPUT_CSV = IMAGE_DIR / \"ocr_results_2025-07-03.csv\"\n",
    "\n",
    "# Quota à¸à¸±à¸™ rate-limit à¸Ÿà¸£à¸µà¹à¸à¸¥à¸™ (~180 req/à¸Šà¸±à¹ˆà¸§à¹‚à¸¡à¸‡)\n",
    "SLEEP_BETWEEN_CALLS = 20       # à¸§à¸´à¸™à¸²à¸—à¸µ à¸à¸±à¸à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸£à¸¹à¸›\n",
    "REQ_TIMEOUT_SEC     = 180      # à¸›à¸à¸•à¸´\n",
    "REQ_TIMEOUT_FALLBACK_SEC = 240 # à¸£à¸­à¸š fallback (à¸¢à¸­à¸¡à¸£à¸­à¸™à¸²à¸™à¸‚à¸¶à¹‰à¸™)\n",
    "\n",
    "# Retry policy\n",
    "MAX_RETRIES   = 6\n",
    "BACKOFF_BASE  = 2.0            # 2,4,8,16,...\n",
    "RETRY_STATUS  = {408, 429, 500, 502, 503, 504}\n",
    "\n",
    "# Image compress policy (à¸›à¸à¸•à¸´)\n",
    "MAX_SIDE_PX        = 2400\n",
    "JPEG_QUALITY       = 90\n",
    "SKIP_COMPRESS_UNDER_MB = 2.5   # à¸–à¹‰à¸²à¹„à¸Ÿà¸¥à¹Œà¸•à¹‰à¸™à¸‰à¸šà¸±à¸š < à¸„à¹ˆà¸²à¸™à¸µà¹‰ (MB) à¸ˆà¸°à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸´à¸¡à¹€à¸¥à¸¢ (à¹„à¸¡à¹ˆà¸šà¸µà¸šà¸­à¸±à¸”)\n",
    "\n",
    "# Image compress policy (fallback à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ˆà¸­ E101/timeout)\n",
    "FALLBACK_MAX_SIDE_PX  = 1600\n",
    "FALLBACK_JPEG_QUALITY = 85\n",
    "\n",
    "# Smart enlarge (à¸‚à¸¢à¸²à¸¢à¹€à¸‰à¸à¸²à¸°à¸ à¸²à¸à¹€à¸¥à¹‡à¸)\n",
    "ENLARGE_MIN_SIDE     = 800     # à¸–à¹‰à¸² short side < à¸„à¹ˆà¸²à¸™à¸µà¹‰ â†’ à¸‚à¸¢à¸²à¸¢\n",
    "ENLARGE_MAX_UPSCALE  = 2.5     # à¸‚à¸¢à¸²à¸¢à¸ªà¸¹à¸‡à¸ªà¸¸à¸” 2.5Ã—\n",
    "\n",
    "# Debug overlay (à¹€à¸›à¸´à¸”à¸Šà¸±à¹ˆà¸§à¸„à¸£à¸²à¸§à¹€à¸à¸·à¹ˆà¸­à¸”à¸¹à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸ˆà¸²à¸ API)\n",
    "IS_OVERLAY_REQUIRED = False    # à¸•à¸±à¹‰à¸‡ True à¹€à¸‰à¸à¸²à¸°à¸•à¸­à¸™ debug\n",
    "\n",
    "# ================= UTIL =================\n",
    "def maybe_enlarge_image(im: Image.Image, min_side: int = ENLARGE_MIN_SIDE, max_upscale: float = ENLARGE_MAX_UPSCALE) -> Image.Image:\n",
    "    \"\"\"à¸‚à¸¢à¸²à¸¢à¸ à¸²à¸à¸–à¹‰à¸²à¹€à¸¥à¹‡à¸à¸à¸§à¹ˆà¸²à¸—à¸µà¹ˆà¸à¸³à¸«à¸™à¸” à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ OCR à¸­à¹ˆà¸²à¸™à¸Šà¸±à¸”à¸‚à¸¶à¹‰à¸™ (à¸„à¸¸à¸¡à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¹ƒà¸«à¸à¹ˆà¹€à¸à¸´à¸™)\"\"\"\n",
    "    w, h = im.size\n",
    "    short_side = min(w, h)\n",
    "    if short_side < min_side:\n",
    "        scale = min(max_upscale, float(min_side) / float(short_side))\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        print(f\"   ğŸ” upscale {w}x{h} â†’ {new_w}x{new_h}\")\n",
    "        im = im.resize((new_w, new_h), resample=Image.LANCZOS)\n",
    "    return im\n",
    "\n",
    "def _prepare_rgb(im: Image.Image) -> Image.Image:\n",
    "    \"\"\"à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ RGB + à¹€à¸„à¸ªà¸ à¸²à¸à¹‚à¸›à¸£à¹ˆà¸‡à¹ƒà¸ª\"\"\"\n",
    "    if im.mode in (\"RGBA\", \"LA\"):\n",
    "        bg = Image.new(\"RGB\", im.size, (255, 255, 255))\n",
    "        bg.paste(im, mask=im.split()[-1])\n",
    "        return bg\n",
    "    if im.mode != \"RGB\":\n",
    "        return im.convert(\"RGB\")\n",
    "    return im\n",
    "\n",
    "def _compress(path: Path, max_side: int, quality: int) -> bytes:\n",
    "    \"\"\"à¸¢à¹ˆà¸­/à¸šà¸µà¸šà¸­à¸±à¸”à¸”à¹‰à¸§à¸¢ LANCZOS + enlarge à¸ªà¸³à¸«à¸£à¸±à¸šà¸ à¸²à¸à¹€à¸¥à¹‡à¸\"\"\"\n",
    "    im = Image.open(path)\n",
    "    im = _prepare_rgb(im)\n",
    "\n",
    "    # à¸‚à¸¢à¸²à¸¢à¸–à¹‰à¸²à¸ à¸²à¸à¹€à¸¥à¹‡à¸à¹€à¸à¸´à¸™à¹„à¸›\n",
    "    im = maybe_enlarge_image(im, min_side=ENLARGE_MIN_SIDE, max_upscale=ENLARGE_MAX_UPSCALE)\n",
    "\n",
    "    w, h = im.size\n",
    "    s = min(1.0, max_side / max(w, h))\n",
    "    if s < 1.0:\n",
    "        im = im.resize((int(w * s), int(h * s)), resample=Image.LANCZOS)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    im.save(buf, format=\"JPEG\", quality=quality, optimize=True)\n",
    "    return buf.getvalue()\n",
    "\n",
    "def compress_primary(path: Path) -> bytes:\n",
    "    return _compress(path, MAX_SIDE_PX, JPEG_QUALITY)\n",
    "\n",
    "def compress_fallback(path: Path) -> bytes:\n",
    "    return _compress(path, FALLBACK_MAX_SIDE_PX, FALLBACK_JPEG_QUALITY)\n",
    "\n",
    "def read_file_bytes(path: Path) -> bytes:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def maybe_prepare_image_bytes(path: Path) -> Tuple[bytes, str]:\n",
    "    \"\"\"\n",
    "    à¸–à¹‰à¸²à¹„à¸Ÿà¸¥à¹Œà¸•à¹‰à¸™à¸‰à¸šà¸±à¸šà¹€à¸¥à¹‡à¸ (< SKIP_COMPRESS_UNDER_MB) â†’ à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸´à¸¡ (à¸£à¸±à¸à¸©à¸²à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”)\n",
    "    à¸–à¹‰à¸²à¹ƒà¸«à¸à¹ˆ â†’ à¸¢à¹ˆà¸­/à¸šà¸µà¸šà¸­à¸±à¸”à¹à¸šà¸š primary (à¸à¸£à¹‰à¸­à¸¡ enlarge à¸–à¹‰à¸²à¸ˆà¸³à¹€à¸›à¹‡à¸™)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        size_mb = os.path.getsize(path) / (1024 * 1024.0)\n",
    "    except:\n",
    "        size_mb = SKIP_COMPRESS_UNDER_MB + 1  # à¸à¸±à¸™à¸à¸¥à¸²à¸” à¸šà¸µà¸šà¸­à¸±à¸”à¹„à¸§à¹‰à¸à¹ˆà¸­à¸™\n",
    "    if size_mb <= SKIP_COMPRESS_UNDER_MB:\n",
    "        # à¹à¸¡à¹‰à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸´à¸¡ à¹€à¸£à¸²à¸à¹‡à¸­à¸¢à¸²à¸ enlarge à¸–à¹‰à¸²à¹€à¸¥à¹‡à¸à¸¡à¸²à¸ â†’ à¸•à¹‰à¸­à¸‡à¹€à¸‚à¹‰à¸²à¸—à¸²à¸‡ compress\n",
    "        # à¹à¸•à¹ˆà¹€à¸à¸·à¹ˆà¸­à¹€à¸£à¸µà¸¢à¸šà¸‡à¹ˆà¸²à¸¢ à¸à¸•à¸´à¸à¸²à¸„à¸·à¸­ à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸”à¸´à¸¡à¹„à¸›à¸à¹ˆà¸­à¸™ (à¸£à¸±à¸à¸©à¸²à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ªà¸¸à¸”)\n",
    "        # à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸œà¹ˆà¸²à¸™/E101 à¸ˆà¸°à¸¡à¸²à¹€à¸‚à¹‰à¸² fallback à¸‹à¸¶à¹ˆà¸‡à¸ˆà¸°à¹€à¸‚à¹‰à¸²à¸—à¸²à¸‡ compress_fallback à¸—à¸µà¹ˆ enlarge à¹ƒà¸«à¹‰\n",
    "        return read_file_bytes(path), \"raw\"\n",
    "    return compress_primary(path), \"compressed\"\n",
    "\n",
    "def should_retry_api_error(body: dict) -> Tuple[bool, str]:\n",
    "    \"\"\"à¸•à¸µà¸„à¸§à¸²à¸¡ error à¸à¸±à¹ˆà¸‡ API à¸—à¸µà¹ˆà¸ªà¹ˆà¸‡à¸à¸¥à¸±à¸šà¸¡à¸²à¸à¸±à¸š status 200 (à¹€à¸Šà¹ˆà¸™ E101)\"\"\"\n",
    "    if not isinstance(body, dict):\n",
    "        return False, \"\"\n",
    "    if body.get(\"IsErroredOnProcessing\"):\n",
    "        msg = body.get(\"ErrorMessage\") or body.get(\"ErrorDetails\") or \"\"\n",
    "        if isinstance(msg, list):\n",
    "            msg = \"; \".join([str(x) for x in msg if x])\n",
    "        msg_low = str(msg).lower()\n",
    "        if \"e101\" in msg_low or \"timed out waiting for results\" in msg_low or \"timeout\" in msg_low:\n",
    "            return True, f\"E101_or_timeout: {msg}\"\n",
    "        if any(k in msg_low for k in [\"busy\", \"overloaded\", \"temporar\", \"please try again\"]):\n",
    "            return True, f\"temporary_api_error: {msg}\"\n",
    "    return False, \"\"\n",
    "\n",
    "def safe_post_with_retry(session: requests.Session, files: Dict, data: Dict, timeout_sec: int) -> Tuple[dict, str]:\n",
    "    \"\"\"\n",
    "    à¸ªà¹ˆà¸‡ request à¸à¸£à¹‰à¸­à¸¡ retry/backoff (+ jitter) à¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ˆà¸­ timeout/connection error/à¸ªà¸–à¸²à¸™à¸°à¸—à¸µà¹ˆà¸„à¸§à¸£à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ\n",
    "    \"\"\"\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = session.post(API_URL, files=files, data=data, timeout=timeout_sec)\n",
    "            if r.status_code == 403:\n",
    "                return {}, \"HTTP 403 (forbidden/rate limit). Please wait and retry.\"\n",
    "            if r.status_code != 200:\n",
    "                if r.status_code in RETRY_STATUS:\n",
    "                    raise ReadTimeout(f\"Temporary status {r.status_code}: {r.text[:200]}\")\n",
    "                return {}, f\"HTTP {r.status_code}: {r.text[:200]}\"\n",
    "\n",
    "            body = r.json()\n",
    "            need_retry, reason = should_retry_api_error(body)\n",
    "            if need_retry:\n",
    "                if attempt == MAX_RETRIES:\n",
    "                    return {}, f\"{reason} after {MAX_RETRIES} retries\"\n",
    "                sleep_s = (BACKOFF_BASE ** (attempt - 1)) + random.uniform(0.0, 0.5)\n",
    "                print(f\"   â†ªï¸ API body error -> retry {attempt}/{MAX_RETRIES-1} in {sleep_s:.1f}s ({reason})\")\n",
    "                time.sleep(sleep_s)\n",
    "                continue\n",
    "\n",
    "            return body, \"\"  # OK\n",
    "        except (ReadTimeout, ConnectTimeout, ReqConnErr) as e:\n",
    "            if attempt == MAX_RETRIES:\n",
    "                return {}, f\"network_or_timeout_after_{MAX_RETRIES}_retries: {repr(e)}\"\n",
    "            sleep_s = (BACKOFF_BASE ** (attempt - 1)) + random.uniform(0.0, 0.5)\n",
    "            print(f\"   â†ªï¸ network/timeout -> retry {attempt}/{MAX_RETRIES-1} in {sleep_s:.1f}s due to: {repr(e)}\")\n",
    "            time.sleep(sleep_s)\n",
    "        except Exception as e:\n",
    "            return {}, f\"unexpected_error: {repr(e)}\"\n",
    "    return {}, \"unreachable_state\"\n",
    "\n",
    "def ocr_one(session: requests.Session, img_path: Path) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    à¸à¸¥à¸¢à¸¸à¸—à¸˜à¹Œ 2 à¸Šà¹ˆà¸§à¸‡:\n",
    "      1) à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œ raw/primary-compress à¸”à¹‰à¸§à¸¢ timeout à¸›à¸à¸•à¸´\n",
    "      2) à¸–à¹‰à¸² body à¹à¸ˆà¹‰à¸‡ E101/timeout à¸«à¸£à¸·à¸­à¹€à¸„à¸£à¸·à¸­à¸‚à¹ˆà¸²à¸¢ timeout -> à¸¥à¸­à¸‡ 'fallback' (enlarge + à¸¢à¹ˆà¸­à¸ à¸²à¸à¹€à¸à¸´à¹ˆà¸¡/à¸¥à¸”à¸„à¸¸à¸“à¸ à¸²à¸ + à¹€à¸à¸´à¹ˆà¸¡ timeout)\n",
    "    \"\"\"\n",
    "    # ----- à¸£à¸­à¸šà¹à¸£à¸ (à¸›à¸à¸•à¸´)\n",
    "    img_bytes, mode = maybe_prepare_image_bytes(img_path)\n",
    "    files = {\"file\": (\"image.jpg\", img_bytes, \"image/jpeg\")}\n",
    "    data = {\n",
    "        \"apikey\": API_KEY,\n",
    "        \"language\": LANGUAGE,       # 'tha' à¸«à¸£à¸·à¸­ 'auto'\n",
    "        \"OCREngine\": ENGINE,        # âœ… à¸à¸²à¸£à¸²à¸¡à¸´à¹€à¸•à¸­à¸£à¹Œà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡\n",
    "        \"isOverlayRequired\": IS_OVERLAY_REQUIRED,\n",
    "        \"scale\": True,\n",
    "        \"detectOrientation\": True,\n",
    "    }\n",
    "\n",
    "    body, err = safe_post_with_retry(session, files, data, timeout_sec=REQ_TIMEOUT_SEC)\n",
    "    if err:\n",
    "        if any(k in err.lower() for k in [\"timeout\", \"timed out\", \"e101\", \"temporary\"]):\n",
    "            print(\"   â†ªï¸ fallback: shrink/enlarge & extend timeout\")\n",
    "        else:\n",
    "            return \"\", f\"{err} (mode={mode})\"\n",
    "    else:\n",
    "        if body.get(\"IsErroredOnProcessing\"):\n",
    "            msg = body.get(\"ErrorMessage\") or body.get(\"ErrorDetails\") or \"unknown_api_error\"\n",
    "            if isinstance(msg, list):\n",
    "                msg = \"; \".join([str(e) for e in msg if e])\n",
    "            msg_low = str(msg).lower()\n",
    "            if (\"e101\" in msg_low) or (\"timed out waiting for results\" in msg_low) or (\"timeout\" in msg_low):\n",
    "                print(\"   â†ªï¸ fallback: E101 in body -> shrink/enlarge & retry\")\n",
    "            else:\n",
    "                return \"\", f\"{msg} (mode={mode})\"\n",
    "        else:\n",
    "            pr = body.get(\"ParsedResults\") or []\n",
    "            text = (pr[0].get(\"ParsedText\") or \"\").strip() if pr else \"\"\n",
    "            return text, \"\"  # success\n",
    "\n",
    "    # ----- à¸£à¸­à¸š fallback (enlarge + à¸¢à¹ˆà¸­à¸ à¸²à¸à¹€à¸à¸´à¹ˆà¸¡/à¸¥à¸”à¸„à¸¸à¸“à¸ à¸²à¸ + à¹€à¸à¸´à¹ˆà¸¡ timeout)\n",
    "    try:\n",
    "        fb_bytes = compress_fallback(img_path)  # à¸ à¸²à¸¢à¹ƒà¸™à¸¡à¸µ enlarge à¹ƒà¸«à¹‰à¸”à¹‰à¸§à¸¢\n",
    "    except Exception as e:\n",
    "        return \"\", f\"fallback_compress_failed: {repr(e)} (mode={mode})\"\n",
    "\n",
    "    files_fb = {\"file\": (\"image.jpg\", fb_bytes, \"image/jpeg\")}\n",
    "    body2, err2 = safe_post_with_retry(session, files_fb, data, timeout_sec=REQ_TIMEOUT_FALLBACK_SEC)\n",
    "    if err2:\n",
    "        return \"\", f\"{err2} (mode=fallback)\"\n",
    "    if body2.get(\"IsErroredOnProcessing\"):\n",
    "        msg2 = body2.get(\"ErrorMessage\") or body2.get(\"ErrorDetails\") or \"unknown_api_error\"\n",
    "        if isinstance(msg2, list):\n",
    "            msg2 = \"; \".join([str(e) for e in msg2 if e])\n",
    "        return \"\", f\"{msg2} (mode=fallback)\"\n",
    "\n",
    "    pr2 = body2.get(\"ParsedResults\") or []\n",
    "    text2 = (pr2[0].get(\"ParsedText\") or \"\").strip() if pr2 else \"\"\n",
    "    return text2, \"\"  # success\n",
    "\n",
    "def load_done_map(csv_path: Path) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"à¸­à¹ˆà¸²à¸™ CSV à¹€à¸”à¸´à¸¡ (à¸–à¹‰à¸²à¸¡à¸µ) à¹€à¸à¸·à¹ˆà¸­ resume: à¸‚à¹‰à¸²à¸¡à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆ textâ‰ '' à¹à¸¥à¸° error=='' \"\"\"\n",
    "    if not csv_path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to read existing CSV ({csv_path}): {repr(e)}\")\n",
    "        return {}\n",
    "    done = {}\n",
    "    for _, row in df.iterrows():\n",
    "        fname = str(row.get(\"filename\"))\n",
    "        if fname and fname.lower() != \"filename\":  # à¸à¸±à¸™à¸à¸£à¸“à¸µà¸«à¸±à¸§à¸•à¸²à¸£à¸²à¸‡\n",
    "            done[fname] = {\n",
    "                \"text\": str(row.get(\"text\") if not pd.isna(row.get(\"text\")) else \"\"),\n",
    "                \"error\": str(row.get(\"error\") if not pd.isna(row.get(\"error\")) else \"\")\n",
    "            }\n",
    "    return done\n",
    "\n",
    "def init_csv(csv_path: Path):\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        csv.DictWriter(f, fieldnames=[\"filename\", \"text\", \"error\"]).writeheader()\n",
    "\n",
    "def append_row(csv_path: Path, row: Dict[str, str]):\n",
    "    csv_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(csv_path, \"a\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        csv.DictWriter(f, fieldnames=[\"filename\", \"text\", \"error\"]).writerow(row)\n",
    "\n",
    "# ================= MAIN =================\n",
    "if __name__ == \"__main__\":\n",
    "    images = sorted([*IMAGE_DIR.glob(\"*.jpg\"), *IMAGE_DIR.glob(\"*.jpeg\"), *IMAGE_DIR.glob(\"*.png\")])\n",
    "    if not images:\n",
    "        print(f\"âš ï¸ No images found in: {IMAGE_DIR}\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    # à¹€à¸•à¸£à¸µà¸¢à¸¡ CSV (à¸–à¹‰à¸²à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µ)\n",
    "    if not OUTPUT_CSV.exists():\n",
    "        init_csv(OUTPUT_CSV)\n",
    "\n",
    "    # à¹‚à¸«à¸¥à¸”à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸µà¹ˆà¹€à¸„à¸¢à¸£à¸±à¸™à¹à¸¥à¹‰à¸§ (resume)\n",
    "    done_map = load_done_map(OUTPUT_CSV)\n",
    "    print(f\"ğŸ” Resuming. Already have {len(done_map)} rows in {OUTPUT_CSV.name}\" if done_map else \"ğŸ†• Starting fresh.\")\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"eve-ocr-runner/2.2\"})\n",
    "\n",
    "    try:\n",
    "        total = len(images)\n",
    "        for i, img in enumerate(images, 1):\n",
    "            prev = done_map.get(img.name)\n",
    "            if prev and (prev.get(\"error\", \"\").strip() == \"\") and (prev.get(\"text\", \"\").strip() != \"\"):\n",
    "                print(f\"[{i}/{total}] {img.name}  â­ï¸  (skip: already OK)\")\n",
    "                continue\n",
    "\n",
    "            print(f\"[{i}/{total}] {img.name}\")\n",
    "            text, err = ocr_one(session, img)\n",
    "\n",
    "            if err:\n",
    "                print(f\"  âš ï¸ {err}\")\n",
    "            else:\n",
    "                preview = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "                print(f\"  âœ… {preview[:140]}{'...' if len(preview) > 140 else ''}\")\n",
    "\n",
    "            append_row(OUTPUT_CSV, {\"filename\": img.name, \"text\": text, \"error\": err})\n",
    "\n",
    "            if i < total:\n",
    "                time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "        print(f\"\\nâœ… Done. Results saved to: {OUTPUT_CSV}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ Interrupted. Partial results are already saved to CSV.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nğŸ’¥ Unexpected error: {repr(e)}\\nPartial results saved to CSV if any.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donut-th",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
